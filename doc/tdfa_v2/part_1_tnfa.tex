\documentclass[AMA,STIX1COL]{WileyNJD-v2}

\articletype{Research Article}

\received{26 April 2016}
\revised{6 June 2016}
\accepted{6 June 2016}

\raggedbottom

%\usepackage{booktabs}

\let\procedure\relax
\let\endprocedure\relax

%\usepackage[ruled]{algorithm2e} % For algorithms

\usepackage[noline, noend, nofillcomment, linesnumbered]{algorithm2e}
%\usepackage[noline, noend, nofillcomment]{algorithm2e}
%\usepackage[noline, noend, nofillcomment, linesnumbered]{algorithm2e}
%    \setlength{\algomargin}{0em}

\usepackage{setspace}

\SetArgSty{textnormal}

% comments in the pseudocode
% note: on my system \texttt is broken with \small font size (too small)
\newcommand\Xcommentfont[1]{\selectfont\textnormal{#1}}
%\newcommand\Xcommentfont[1]{\fontsize{9pt}{0pt}\selectfont\texttt{#1}}
\SetCommentSty{Xcommentfont}
\SetNoFillComment

\let\oldnl\nl % Store \nl in \oldnl
\newcommand{\nonl}{\renewcommand{\nl}{\let\nl\oldnl}} % Remove line number for one line

\SetNlSty{textnormal}{}{}

\renewcommand{\algorithmcfname}{ALGORITHM}
%\SetAlFnt{\small}
%\SetAlCapFnt{\small}
%\SetAlCapNameFnt{\small}
%\SetAlCapHSkip{0pt}
%\IncMargin{-\parindent}

\usepackage[utf8]{inputenc}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{accents}
\usepackage{mathtools}
\usepackage{graphicx}
\usepackage{enumitem}
\usepackage[justification=centering]{caption}
\usepackage{url}
\usepackage{vwcol}
\usepackage[section]{placeins}

\newcommand{\Xl}{\langle}
\newcommand{\Xr}{\rangle}
\newcommand{\Xm}{\langle\!\rangle}
\newcommand{\Xset}{\!\leftarrow\!}
\newcommand{\Xund}{\rule{.4em}{.4pt}}
\newcommand{\Xlb}{[\![}
\newcommand{\Xrb}{]\!]}
\newcommand{\Xmap}{\!\mapsto\!}
\newcommand{\XB}{\mathcal{B}}
\newcommand{\XD}{\mathcal{D}}
\newcommand{\XE}{\mathcal{E}}
\newcommand{\XF}{\mathcal{F}}
\newcommand{\XI}{\mathcal{I}}
\newcommand{\XPT}{\XP\!\XT}
\newcommand{\XIT}{\XI\!\XT}
\newcommand{\XIR}{\XI\!\XR}
\newcommand{\XL}{\mathcal{L}}
\newcommand{\XN}{\mathcal{N}}
\newcommand{\XM}{\mathcal{M}}
\newcommand{\XO}{\mathcal{O}}
\newcommand{\XP}{\mathcal{P}}
\newcommand{\XR}{\mathcal{R}}
\newcommand{\XS}{\mathcal{S}}
\newcommand{\XT}{\mathcal{T}}
\newcommand{\XX}{\mathcal{X}}
\newcommand{\YB}{\mathbb{B}}
\newcommand{\YC}{\mathbb{C}}
\newcommand{\YK}{\mathbb{K}}
\newcommand{\YF}{\mathbb{F}}
\newcommand{\YN}{\mathbb{N}}
\newcommand{\YT}{\mathbb{T}}
\newcommand{\YQ}{\mathbb{Q}}
\newcommand{\YP}{\mathbb{P}}
\newcommand{\YZ}{\mathbb{Z}}
\newcommand{\PT}{PT}
\newcommand{\PE}{P\!E}
\newcommand{\PR}{P\!R}
\newcommand{\IPT}{I\!PT}
\newcommand{\IRE}{I\!RE}

\newcommand{\Xstirling}[2]{\genfrac{\{}{\}}{0pt}{}{#1}{#2}}
\newcommand*{\Xbar}[1]{\overline{#1}}
\newcommand{\pnorm}[2]{\|{#1}\|^{Pos}_{#2}}
\newcommand{\snorm}[2]{\|{#1}\|^{Sub}_{#2}}

\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

\setlist{nosep}
%\setlength{\parskip}{0.5em}

\newenvironment{Xfig}
    {\par\medskip\noindent\minipage{\linewidth}\begin{center}}
    {\end{center}\endminipage\par\medskip}
\newenvironment{Xtab}
    {\par\medskip\noindent\minipage{\linewidth}\begin{center}}
    {\end{center}\endminipage\par\medskip}

\setlength{\parindent}{0pt}
\setlength{\belowcaptionskip}{-1em}

%\theoremstyle{definition}
\newtheorem{Xdef}{Definition}
\newtheorem{XThe}{Theorem}
\newtheorem{XLem}{Lemma}
\newtheorem{Xobs}{Observation}


\begin{document}

\title{Efficient POSIX Submatch Extraction on NFA}

\author[1]{Angelo Borsotti}
\author[2]{Ulya Trofimovich}

\address[1]{\email{angelo.borsotti@mail.polimi.it}}
\address[2]{\email{skvadrik@gmail.com}}

\abstract[Summary]{
We give an algorithm for regular expression parsing and submatch extraction with POSIX longest-match semantics.
The algorithm is based on Okui-Suzuki disambiguation procedure with a number of non-trivial extensions and improvements.
We study other NFA-based algorithms
and show that the algorithm by Kuklewicz is slower in practice,
and the backward matching algorithm by Cox is incorrect.
%
Our algorithm works in worst-case $O(n \, m^2 \, t)$ time and $O(m^2)$ space,
where $n$ is the length of input, $m$ is the size of regular expression
and $t$ is the number of capturing groups plus enclosing subexpressions.
%
Benchmarks show that in practice our algorithm is 2-10x slower than leftmost greedy matching.
%
We discuss a lazy variation that is much faster, but requires memory proportional to the size of input.
}

\keywords{Regular Expressions, Parsing, Submatch Extraction, Finite-State Automata, POSIX}

%\jnlcitation{\cname{
%\author{U. Trofimovich},
%(\cyear{2017}),
%\ctitle{Fast Submatch Extraction in Lexer Generators},
%\cjournal{Q.J.R. Meteorol. Soc.},
%\cvol{2017;00:1--6}.}

\maketitle

\section{Introduction}

In this paper we study NFA-based approaches to the problem of POSIX regular expression parsing and submatch extraction.
A number of algorithms have been proposed in recent years,
but not all of them were thoroughly studied and formalized,
and some support only a subset of POSIX regular expressions.
Our goal is to compare different approaches,
pick the most efficient one,
extend it on the full range of POSIX regular expressions
and provide a practical matching algorithm.
%
It should be noted that there exists a totally different approach based on Brzozowski derivatives.
We choose to focus on NFA-based approach for the following reasons:
first, we feel that both approaches deserve to be studied and formalized;
and second, in our experience derivative-based approach is much slower in practice
(possibly due to an imperfect implementation, but we also discuss theoretical bounds below).
%
Both NFAs and derivatives can be used to construct DFAs with POSIX longest-match semantics [SL13] [Bor15] [Tro17].
The resulting DFA-based algorithms are very fast, because there is no run-time overhead on disambiguation.
However, DFA construction is not always viable due to its exponential worst-case complexity,
and if viable, it needs to be efficient.
Therefore we concentrate on NFA-based algorithms
that can be used directly for matching, or serve as a basis for DFA construction.
We give an overview of existing algorithms, including some that are incorrect but interesting.
%
\iffalse
The difficulty of POSIX longest-match semantics is caused by our inability to predict correct match results at the point where they diverge.
Consider regular expression \texttt{(a\{2\}|a\{3\}|a\{5\})*} and string \texttt{a...a}.
Submatch on the last iteration varies with the length of input:
it equals \texttt{aaaaa} for $5n$-character string,
\texttt{aa} for strings of length $5n - 3$ and $5n - 1$,
and \texttt{aaa} for strings of length $5n - 2$ and $5n + 1$ ($n \in \YN$).
Variation continues infinitely with a period of five characters.
The period is a property of regular expression;
in our example we can change it by choosing different counter values.
POSIX matching algorithms deal with this difficulty in different ways.
On one side we have generic, but inefficient approaches like exhaustive backtracking and dynamic programming.
On the other side we have algorithms based on deterministic automata [SL13] [Bor15] [Tro17]
that are very efficient at run-time, because all disambiguation is done in advance and built into DFA.
However, DFA construction is not always viable due to its exponential worst-case complexity,
and if viable, it needs to be efficient.
Therefore in this work we concentrate on practical NFA-based algorithms
that can be used directly for matching or serve as a basis for DFA construction.
We give an overview of existing algorithms, including some that are incorrect, but interesting.
\fi

\subparagraph{Laurikari, 2001 (incorrect).}

Laurikari algorithm is based on TNFA, which is an $\epsilon$-NFA with tagged transitions [Lau01].
Each submatch group is represented with a pair of \emph{tags} (opening and closing).
Disambiguation is based on minimizing the value of opening tags and maximizing tha value of closing tags, where
different tags have priority according to POSIX subexpression hierarchy.
Notably, Laurikari used the idea of topological order to avoid worst-case exponential time of $\epsilon$-closure construction.
His algorithm doesn't track history of iteration subexpressions and gives incorrect result in cases like \texttt{(a|aa)*} and string \texttt{aa}.
Reported computational complexity is $O(n \, m \, c \, t \, log(t))$, where
$n$ is input length,
$m$ is TNFA size,
$c$ is the time for comparing tag values
and $t$ is the number of tags.
Memory requirement is $O(m \, t)$.

\subparagraph{Kuklewicz, 2007.}

Kuklewicz fixed Laurikari algorithm by introducing \emph{orbit} tags for iteration subexpressions.
He gave only an informal description [Kuk07], but the algorithm was later formalized in [Tro17].
It works in the same way as Lauirikari algorithm,
except that comparison of orbit tags is based on their previous history, not just the most recent value.
The clever idea is to avoid recording full history
by compressing histories in a matrix of size $t \times m$, where $m$ is TNFA size and $t$ is the number of tags.
$t$-Th row of the matrix represents ordering of closure states with respect to $t$-th tag
(with possible ties --- different states may have the same order).
Matrix is updated at each step using continuations of tag histories.
The algorithm requires $O(m \, t)$ memory and $O(n \, m \, t \, (m + t \, log(m))$ time, where $n$ is the input length
($\epsilon$-closure takes $O(m^2 \, t)$ assuming worst-case optimal algorithm,
and matrix update takes $O(m \, log(m) \, t^2)$ because for $t$ tags we need to sort $m$ states with $O(t)$ comparison function).
%Kuklewicz disambiguation is combined with Laurikari determinization [Lau00] in [Tro17].

\subparagraph{Cox, 2009 (incorrect).}

Cox came up with the idea of backward POSIX matching,
which is based on the observation that it is easier to maximize submatch on the last (or most recent) iteration than on the first one,
because we do not need to track the full history of previous iterations.
The algorithm consumes the input string from right to left
and tracks two pairs of offsets for each submatch group:
the \emph{active} pair of most recent offsets (used in disambiguation),
and the \emph{final} pair of offsets on the backwards-first (i.e. the last) iteration.
The algorithm gives incorrect results under two conditions:
(1) ambiguous matches have equal offsets on some iteration,
and (2) comparison happens too late, when active offsets have already been updated and the difference is erased.
We found that such situations may occur for two reasons.
First, $\epsilon$-closure algorithm may compare ambiguous paths \emph{after} their join point,
when both paths have a common suffix with tagged transitions.
This is the case with Cox prototype implementation [Cox09]; for example, it gives incorrect results for \texttt{(aa|a)*} and string \texttt{aaaaa}.
Most of such failures can be repaired by exploring states in topological order,
but topological order does not exist in the presence of $\epsilon$-loops.
The second reason is bounded repetition: ambiguous paths may not have an intermedite join point at all.
For example, in case of \texttt{(aaaa|aaa|a)\{3,4\}} and string \texttt{aaaaaaaaaa}
we have matches \texttt{(aaaa)(aaaa)(a)(a)} and \texttt{(aaaa)(aaa)(aaa)}
with different number of iterations.
If bounded repetion is modelled by duplicating sub-automata and making the last repetition optional,
then by the time ambiguous paths meet both have active offsets \texttt{(0,4)}.
Despite the flaw, Cox algorithm is interesting: if somehow delayed comparison problem was fixed, it would work.
The algorithm requires $O(m \, t)$ memory and $O(n \, m^2 \, t)$ time
(assuming worst-case optimal closure algorithm),
where $n$ is the input length,
$m$ it the size of regular expression
and $t$ is the number of submatch groups plus enclosing subexpressions.

\subparagraph{Okui and Suzuki, 2013.}

Okui and Suzuki view disambiguation problem from the point of comparison of parse trees [OS13].
Ambiguous trees have the same sequence of leaf symbols, but their branching structure is different.
Each subtree corresponds to a subexpression.
The \emph{norm} of a subtree (the number of leaf symbols in it) equals to submatch length.
Longest match corresponds to a tree in which the norm of each subtree in leftmost in-order traversal is maximized.
The clever idea of Okui and Suzuki is to relate the norm of subtrees to their \emph{height} (distance from the root).
Namely, if we walk through the leaves of two ambiguous trees, tracking the height of each complete subtree,
then at some step heights will diverge:
subtree with a smaller norm will already be complete, but the one with a greater norm will not.
Height of subtrees is easy to track by attibuting it to parentheses and encoding in automaton transitions.
Okui and Suzuki use PAT --- $\epsilon$-free position automaton with transitions labelled by sequences of parentheses.
Disambiguation is based on comparing parentheses along ambiguous PAT paths.
Similar to Kuklewicz, Okui and Suzuki avoid recording full-length paths
by pre-comparing them at each step and storing comparison results in a pair of matrices indexed by PAT states.
The authors report complexity $O(n(m^2 + c))$, where
$n$ is the input length,
$m$ is the number of occurrences of the most frequent symbol in regular expression
and $c$ is the number of submatch groups and repetition operators.
However, this estimate leaves out the constuction of PAT and precomputation of precedence relation.
Memory requirement is $O(m^2)$.
Okui-Suzuki disambiguation is combined with Berry-Sethi construction in [Bor15] in construction of parsing DFA.

\subparagraph{Sulzmann and Lu, 2013.}

Sulzmann and Lu based their algorithm on Brzozowski derivatives [??]
(correctness proof is given by Ausaf, Dyckhoff and Urban [??]).
The algorithm unfolds a regular expression into a sequence of derivatives
(each derivative is obtained from the previous one by consuming the next input symbol),
and then folds it back into a parse tree
(the tree for the previous derivative is built from the tree for the next derivative by ``injecting'' the corresponding input symbol).
In practice, Sulzmann and Lu fuse backward and forward passes,
which allows to avoid potentially unbounded memory usage on keeping all intermediate derivatives.
The algorithm is unique in that it does not require explicit disambiguation: longest match is obtained by construction.
Time and space complexity is not entirely clear.
In [??] Sulzmann and Lu consider the size of the regular expression as a constant.
In [??] they give more precise estimates: $O(2^m \, t)$ space and $O(n \, log(2^m) \, 2^m \, t^2)$ time,
where $m$ is the size of the regular expression,
$n$ is the length of input
and $t$ the number of submatch groups (the authors do not differentiate between $m$ and $t$).
However, this estimate assumes worst-case $O(2^m)$ derivative size and on-the-fly DFA construction.
The authors also mention a better $O(m^2)$ theoretical bound for derivative size.
If we adopt it and exclude DFA consturuction, we get $O(m^2 \, t)$ memory requirement and $O(n \, m^2 \, t^2)$ time,
which seems reasonably close to NFA-based approaches.
\\

Undoubtedly there are other approaches,
but many of them produce incorrect results or require memory proportional to the length of input
(e.g. Glibc implementation [??]).
Of the two correct NFA-based approaches, Okui-Suzuki appears to be faster in practice.
However, it should be noted that the two approaches have much in common:
both compare partial matches incrementally at each step,
only Kuklewicz considers histories of different tags separately.
%
Our contributions are the following:
\\[-0.5em]

\begin{itemize}[itemsep=0.5em]

    \item We extend Okui-Suzuki algorithm on the case of partially ordered parse trees.
        The original algorithm considers all subexpressions as submatch groups,
        which means a lot of overhead if only a few groups are needed.

    \item We extend Okui-Suzuki algorithm on the case of bounded repetition.

    \item We combine Okui-Suzuki algorithm with Laurikari TNFA.
        It allows us to omit the preprocessing step
        at the cost of $\epsilon$-closure construction,
        which may be preferable in cases when preprocessing time is included in match time.

    \item We introduce \emph{negative tags} that allow us to handle
        no-match situation in the same way as match.
        In particular, this removes the need to fix obsolete offsets that remain from earlier iterations,
        in cases like \texttt{(a(b)?)*} and string \texttt{aba}.

    \item We consider $\epsilon$-closure construction as a shortest-path problem
        and show that path concatenation is right-distributive over path comparison
        for the subset of paths considered by closure algorithm.
        This justifies the use of Goldberg-Radzik algorithm based on the idea of topological order,
        which has worst-case optimal quadratic complexity in the size of closure
        and guaranteed linear complexity if the closure has no $\epsilon$-loops.
        This is an improvement over naive exhaustive depth-first search with backtracking,
        and also an improvement over Laurikari algorithm as shown in [Tro17].

    \item We give a faster algorithm for updating precedence matrix.
        The straightforward algorithm described by Okui and Suzuki involves pairwise comparison of all states in closure
        and takes $O(m^2 \, t)$ time, assuming $m$ states and $O(t)$ comparison function.
        We show a pathological example \texttt{((a?)\{0,1000\})*} where $t \approx m$.
        Our algorithm takes $O(m^2)$ time.

    \item We discuss a \emph{lazy} variation of our algorithm
        that reduces the overhead on disambiguation
        at the cost of memory usage that grows with the length of input.
        The lazy algorithm is simpler than the original and may used for not-too-long inputs.

    \item We provide a C++ implementation of different NFA-based algorithms
        and benchmark them against each other and against a ``baseline'' leftmost greedy implementation.
    \\[-0.5em]
\end{itemize}

The rest of this paper is arranged as follows.
In section \ref{section_main} we present the main idea and the skeleton of our algorithm.
In section \ref{section_formalization} we provide theoretical foundations for the rest of the paper.
After that, we go into specific details:
section \ref{section_closure} is concerned with $\epsilon$-closure construction,
section \ref{section_pathtree} discusses data structures used to represent TNFA paths,
section \ref{section_results} discusses possible output formats (parse trees or POSIX-style offsets),
section \ref{section_comparison} gives the core disambiguation algorithms,
section \ref{section_lazy} concerns lazy disambiguation
and section \ref{section_tnfa} gives specific TNFA construction.
The remaining sections \ref{section_benchmarks} and \ref{section_conclusion}
contain benchmarks, conclusions and directions for future work.

\section{The main idea}\label{section_main}

Our algorithm is based on four cornerstone concepts:
regular expressions, parse trees, parenthesized expressions and tagged NFA.
%
First, we formalize the matching problem
by giving the usual interpretation of regular expressions as sets of parse trees.
%
Next, we define POSIX disambiguation semantics in terms of order on parse trees.
This definition reflects POSIX standard,
but it is too high-level to be used in a practical matching algorithm.
%
Therefore we go from parse trees to their linearized representation --- parenthesized expressions.
We define order on parenthesized expressions and show its equivalence to the order on parse trees.
The latter definition is more low-level and can be easily converted to an efficient comparison procedure.
%
Finally, we construct TNFA and map parenthesized expressions to its paths,
which allows us to compare ambiguous paths using the definition of order on parenthesized expressions.
%
Below are the four basic definitions and the skeleton of the algorithm.
In later sections we formalize relations between different representations and fill in all the details.

    \begin{Xdef}
    \emph{Regular expressions (RE)} over finite alphabet $\Sigma$, denoted $\XR_\Sigma$:
    \begin{enumerate}
        \item
          Empty RE $\epsilon$ and
          unit RE $\alpha$ (where $\alpha \in \Sigma$) are in $\XR_\Sigma$.
        \item If $e_1, e_2 \in \XR_\Sigma$, then
          union $e_1 | e_2$,
          product $e_1 e_2$,
          repetition $e_1^{n, m}$ (where $0 \leq n \leq m \leq \infty$), and
          submatch group $(e_1)$
          are in $\XR_\Sigma$.
    \end{enumerate}
    \end{Xdef}


    \begin{Xdef}
    \emph{Parse trees (PT)} over finite alphabet $\Sigma$, denoted $\XT_\Sigma$:
    \begin{enumerate}
        \item
          Nil tree ${\varnothing}^i$,
          empty tree ${\epsilon}^i$ and
          unit tree ${\alpha}^i$ (where $\alpha \in \Sigma$ and $i \in \YZ$)
          are in $\XT_\Sigma$.
        \item If $t_1, \dots, t_n \in \XT_\Sigma$ (where $n \geq 1$, and $i \in \YZ$), then
          ${T}^i(t_1, \dots, t_n)$
          is in $\XT_\Sigma$.
    \end{enumerate}
    \end{Xdef}


    \begin{Xdef}
    \emph{Parenthesized expressions (PE)} over finite alphabet $\Sigma$, denoted $\XP_\Sigma$:
    \begin{enumerate}
        \item
            Nil expression $\Xm$,
            empty expression $\epsilon$ and
            unit expression $\alpha$ (where $\alpha \in \Sigma$)
            are in $\XP_\Sigma$.
        \item If $e_1, e_2 \in \XP_\Sigma$, then
            $e_1 e_2$ and
            $\Xl e_1 \Xr$
            are in $\XP_\Sigma$.
    \end{enumerate}
    \end{Xdef}


    \begin{Xdef}
    \emph{Tagged Nondeterministic Finite Automaton (TNFA)}
    is a structure $(\Sigma, Q, T, \Delta, q_0, q_f)$, where:
    \begin{itemize}
        \item[] $\Sigma$ is a finite set of symbols (\emph{alphabet})
        \item[] $Q$ is a finite set of \emph{states}
        \item[] $T \subset \YN \times \YZ$ is a mapping of \emph{tags} to their submatch groups
        \item[] $\Delta = \Delta^\Sigma \sqcup \Delta^\epsilon$ is the \emph{transition} relation,
            consisting of two parts:
        \begin{itemize}
            \item[] $\Delta^\Sigma \subseteq Q \times \Sigma \times \{\epsilon\} \times Q$ (transitions on symbols)
            \item[] $\Delta^\epsilon \subseteq Q \times \YN \times \big( \YZ \cup \{\epsilon\} \big) \times Q$
                ($\epsilon$-transitions, where $\forall (q, n, \Xund, \Xund), (q, m, \Xund, \Xund) \in \Delta^\epsilon: n \neq m$)
        \end{itemize}
        \item[] $q_0 \in Q$ is the \emph{initial} state
        \item[] $q_f \in Q$ is the \emph{final} state
    \end{itemize}
    \end{Xdef}

As the reader might notice, our definitions are subtly different from the usual ones in literature.
Regular expressions are extended with submatch operator
and generalized repetition (note that it is not just syntactic sugar: in POSIX \texttt{(a)(a)} is semantically different from \texttt{(a)\{2\}},
and \texttt{(a)} in not the same as \texttt{a}).
Parse trees have a special \emph{nil-tree} constructor
and an upper index, which allows us to distinguish between submatch and non-submatch subtrees.
Mirroring parse trees, parenthesized expressions also have a special \emph{nil-parenthesis}.
TNFA is in essence a nondeterministic finite-state transducer
in which some of the $\epsilon$-transitions are marked with \emph{tags} ---
integer numbers that denote opening and closing parentheses of submatch groups.
For $i$-th group, opening tag is $2i - 1$ and closing tag is $2i$ (where $i \in \YN$).
Tags can be negative, which represents the absence of match and corresponds to nil-parenthesis $\Xm$ and nil-tree $\varnothing$.
Additionally, all $\epsilon$-transitions are marked with \emph{priority}
which allows us to impose specific order of TNFA traversal
(all $\epsilon$-transitions from the same state have different priority).
\\

\begin{algorithm}[H] \DontPrintSemicolon \SetKwProg{Fn}{}{}{} \SetAlgoInsideSkip{medskip}
\setstretch{0.8}
\Fn {$\underline{match \big( N \!\!=\! (\Sigma, Q, T, \Delta, q_0, q_f), \; \alpha_1 \!\hdots\! \alpha_n \big)} \smallskip$} {

    $B, D : \text{square matrices in } \YZ^{|Q| \times |Q|}, \; U: \text{path context}$ \;
    $r_0 = initial \Xund result(T)$ \;
    $u_0 = empty \Xund path(\,)$ \;
    $X = \big\{ (q_0, \varnothing, u_0, r_0) \big\}, \; i = 1$ \;

    \BlankLine
    \While {$i \leq n \wedge X \neq \emptyset$} {
        $X = closure(N, X, U, B, D)$ \;
        $X = update \Xund result(T, X, U, i, \alpha_i)$ \;
        $(B, D) = update \Xund ptables(N, X, U, B, D)$ \;
        $X = \big\{ (q, o, u_0, r) \mid (o, \Xund, \Xund, r) \in X \wedge (o, \alpha_i, \epsilon, q) \in \Delta^\Sigma \big\}$ \;
        $i = i + 1$ \;
    }

    \BlankLine
    $X = closure(N, X, U, B, D)$ \;
    \If {$(q_f, \Xund, u, r) \in X$} {
        \Return $f\!inal \Xund result (T, U, u, r, n)$
    } \lElse {
        \Return $\varnothing$
    }

    \BlankLine
}
%\caption{Skeleton of the matching algorithm.}
\caption{TNFA simulation on a string.}
\end{algorithm}
\medskip

The algorithm takes automaton $N$ and string $\alpha_1 \!\hdots\! \alpha_n$ as input,
and outputs match result is some form: it can be a parse tree or a POSIX array of offsets,
but for now we leave it unspecified and hide behind functions
$initial \Xund result ()$, $update \Xund result ()$ and $f\!inal \Xund result ()$.
The algorithm works by consuming input symbols,
tracking a set of active \emph{configurations}
and updating \emph{precedence tables} $B$ and $D$.
Configuration is a tuple $(q, o, u, r)$.
The first component $q$ is a TNFA state that is unique for each configuration in the current set.
Components $o$ and $u$ keep information about the path by which $q$ was reached:
$o$ is the \emph{origin} state used as index in precedence tables,
and $u$ is a path fragment constructed by $closure()$.
Specific representation of path fragments is hidden behind path context $U$ and function stub $empty \Xund path ()$.
Finally, $r$-component is a partial match result associated with state $q$.
Most of the real work happens inside of $closure()$ and $update \Xund ptables ()$, both of which remain undefined for now.
The $closure()$ function builds $\epsilon$-closure of the current configuration set:
it explores all states reachable by $\epsilon$-transitions from the $q$-components
and tracks the best path to each reachable state.
The $update \Xund ptables ()$ function
performs pairwise comparison of all configurations in the new set,
recording results in $B$ and $D$ matrices.
On the next step $q$-components become $o$-components.
If paths originating from current configurations meet on some future step,
$closure ()$ will use origin states to lookup comparison results in $B$ and $D$ matrices.
If the paths do not meet, then comparison performed by $update \Xund ptables ()$ is redundant ---
unfortunately we do not know in advance which configurations will spawn ambiguous paths.
\\

%\vfill\null

\section{Formalization}\label{section_formalization}

In this section we establish the relation between all intermediate representations.
First of all, we rewrite REs in a form that makes submatch information explicit:
to each subexpression we assign an \emph{implicit} and \emph{explicit} submatch index, where
explicit indices enumerate submatch groups (for all other subexpressions they are zero),
and implicit indices enumerate submatch groups and subexpressions that are not submatch groups,
but contain nested or sibling groups and need to be considered by disambiguation.
This form reflects POSIX standard, which states that
submatch extraction applies only to parenthesized subexpressions,
but the longest-match rule applies to all subexpressions regardless of parentheses.

    \begin{Xdef}
    \emph{Indexed regular expressions (IRE)} over finite alphabet $\Sigma$, denoted $\XIR_\Sigma$:
    \begin{enumerate}
        \item
          Empty IRE $(i, j, \epsilon)$ and
          unit IRE $(i, j, \alpha)$, where $\alpha \in \Sigma$ and $i, j \in \YZ$,
          are in $\XIR_\Sigma$.

        \item If $r_1, r_2 \in \XIR_\Sigma$ and $i, j \in \YZ$, then
          union $(i, j, r_1 \mid r_2)$,
          product $(i, j, r_1 \cdot r_2)$ and
          repetition $(i, j, r_1^{n, m})$, where $0 \leq n \leq m \leq \infty$,
          are in $\XIR_\Sigma$.
    \end{enumerate}
    \end{Xdef}

Function $\IRE$ transforms RE into IRE.
It is defined via a composition of two functions,
$mark()$ that transforms RE into IRE with submatch indices in the boolean range $\{0, 1\}$,
and $enum()$ that substitutes boolean indices with consecutive numbers.
%$\IRE(e) = r$ where $(\Xund, \Xund, r) = enum(1, 1, mark(e))$.
%Note that we consider $(e)$ as a special case of repetition $(e)^{1,1}$:
%this allows us to handle all parenthesized sub-RE uniformly.
An example of constructing an IRE from a RE is given on figure \ref{fig_mark_enum}.
%The reverse transformation is also possible by erasing all indices
%and adding parentheses around subexpressions with nonzero explicit submatch index.
%Therefore RE and IRE are equivalent representations.

    \begin{align*}
    &\begin{aligned}
        mark &: \XR_\Sigma \longrightarrow \XIR_\Sigma \\
        mark &(x) \mid_{x \in \{\epsilon, \alpha\}} = (0, 0, x) \\[-0.2em]
        %
        mark &(e_1 \circ e_2) \mid_{\circ \in \{|,\cdot\}} = (i, 0,
            (i, j_1, r_1) \circ
            (i, j_2, r_2)
            ) \\[-0.2em]
            &\text{where }            (i_1, j_1, r_1) = mark(e_1) \\[-0.2em]
            &\space{\hphantom{where }}(i_2, j_2, r_2) = mark(e_2) \\[-0.2em]
            &\space{\hphantom{where }}i = i_1 \vee i_2 \\[-0.2em]
        %
        mark &(e^{n, m}) \mid_{e = (e_1)} = (1, 0, (1, 1, r)) \\[-0.2em]
            &\text{where } (\Xund, \Xund, r) = mark(e_1) \\[-0.2em]
        %
        mark &(e^{n, m}) \mid_{e \neq (e_1)} = (i, 0, (i, j, r)) \\[-0.2em]
            &\text{where } (i, j, r) = mark(e) \\[-0.2em]
        %
        mark &((e)) = mark((e)^{1, 1})
    \end{aligned}
    %
    &&\begin{aligned}
        enum &: \YZ \times \YZ \times \XIR_\Sigma \longrightarrow \YZ \times \YZ \times \XIR_\Sigma \\
        enum &(\bar{i}, \bar{j}, (i, j, x)) \mid_{x \in \{\epsilon, \alpha\}}
            = (\bar{i} + i, \bar{j} + j, (\bar{i} \times i, \bar{j} \times j, x))
        \\[-0.2em]
        enum &(\bar{i}, \bar{j}, (i, j, r_1 \circ r_2)) \mid_{\circ \in \{|,\cdot\}}
            = (i_2, j_2, (\bar{i} \times i, \bar{j} \times j, \bar{r}_1 \circ \bar{r}_2)) \\[-0.2em]
            &\text{where }            (i_1, j_1, \bar{r}_1) = enum(\bar{i} + i, \bar{j} + j, r_1) \\[-0.2em]
            &\space{\hphantom{where }}(i_2, j_2, \bar{r}_2) = enum(i_1, j_1, r_2)
        \\[-0.2em]
        enum &(\bar{i}, \bar{j}, (i, j, r^{n,m})) = (i_1, j_1, (\bar{i} \times i, \bar{j} \times j, \bar{r}^{n,m})) \\[-0.2em]
            &\text{where }
                (i_1, j_1, \bar{r}) = enum(\bar{i} + i, \bar{j} + j, r)
        \\[-0.2em]
        \\[-0.2em]
        \IRE &: \XR_\Sigma \rightarrow \XIR_\Sigma \\[-0.2em]
        \IRE&(e) = r \\[-0.2em]
            &\text{where }(\Xund, \Xund, r) = enum(1, 1, mark(e))
        \\[-0.2em]
    \end{aligned}
    \end{align*}
    \medskip

The relation between regular expressions and parse trees is given by the operator $\PT$.
Each IRE denotes a set of PTs:

    \begin{align*}
        \PT &: \XIR_\Sigma \rightarrow 2^{\XT_\Sigma}
        \\
        \PT\big((i, \Xund, \epsilon)\big) &= \{ {\epsilon}^{i} \}
        \\[-0.2em]
        \PT\big((i, \Xund, \alpha)\big) &= \{ {\alpha}^{i} \}
        \\[-0.2em]
        \PT\big((i, \Xund, (i_1, j_1, r_1) \mid (i_2, j_2, r_2))\big) &=
            \big\{ {T}^{i}(t, \varnothing^{i_2}) \mid t \in \PT\big((i_1, j_1, r_1)\big) \big\} \cup
            \big\{ {T}^{i}(\varnothing^{i_1}, t) \mid t \in \PT\big((i_2, j_2, r_2)\big) \big\}
        \\[-0.2em]
        \PT\big((i, \Xund, (i_1, j_1, r_1) \cdot (i_2, j_2, r_2))\big) &=
            \big\{ {T}^{i}(t_1, t_2) \mid
                t_1 \in \PT\big((i_1, j_1, r_1)\big),
                t_2 \in \PT\big((i_2, j_2, r_2)\big)
            \big\} \\[-0.2em]
        \PT\big((i, \Xund, (i_1, j_1, r_1)^{n, m})\big) &=
            \begin{cases}
                \big\{ {T}^{i}(t_1, \dots, t_m) \mid t_k \in \PT\big((i_1, j_1, r_1)\big) \;
                    \forall k = \overline{1, m} \big\} \cup \{ {T}^{i}(\varnothing^{i_1}) \} &\text{if } n = 0 \\[-0.2em]
                \big\{ {T}^{i}(t_n, \dots, t_m) \mid t_k \in \PT\big((i_1, j_1, r_1)\big) \;
                    \forall k = \overline{n, m} \big\} &\text{if } n > 0
            \end{cases}
    \end{align*}
    \medskip

We write $str(t)$ to denote the string formed by concatenation of all alphabet symbols in the left-to-right traversal of $t$,
and $\PT(r, w)$ denotes the set $\big\{ t \in \PT(\IRE(r)) \mid str(t) = w \big\}$ of all PTs for a RE $r$ and a string $w$.

    \begin{Xdef}\label{ambiguity_of_parse_trees}
    \emph{Ambiguity of parse trees.}
    PTs $s$ and $t$ are \emph{ambiguous} iff $s \neq t$ and $s, t \in PT(r, w)$ for some RE $r$ and string $w$.
    \end{Xdef}

Following \ref{OS13}, we assign \emph{positions} to the nodes of RE and PT.
The root position is $\Lambda$, and position of the $i$-th subtree of a tree with position $p$ is $p.i$
(we shorten $\|t\|_\Lambda$ as $\|t\|$).
The \emph{length} of position $p$, denoted $|p|$, is defined as $0$ for $\Lambda$ and $|p| + 1$ for $p.i$.
%The set of all positions is denoted $\XP$.
The subtree of a tree $t$ at position $p$ is denoted $t|_p$.
Position $p$ is a \emph{prefix} of position $q$ iff $q = p.p'$ for some $p'$,
and a \emph{proper prefix} if additionaly $p \neq q$.
Position $p$ is a \emph{sibling} of position $q$ iff $q = q'.i, p = q'.j$ for some $q'$ and $i,j \in \YN$.
Positions are ordered lexicographically.
The set of all positions of a tree $t$ is denoted $Pos(t)$.
Additionally, we define a set of \emph{submatch positions} as
$Sub(t) = \big\{ p \mid \exists t|_p = s^i : i \neq 0 \big\}$ ---
a subset of $Pos(t)$ that contains positions of subtrees with nonzero implicit submatch index.
Intuitively, this is the set of positions important from disambiguation perspective:
in the case of ambiguity we do not need to consider the full trees,
just the relevant parts of them.
%
PTs have two definitions of norm, one for $Pos$ and one for $Sub$,
which we call \emph{p-norm} and \emph{s-norm} respectively:

\begin{figure}\label{fig_mark_enum}
\includegraphics[width=\linewidth]{img/mark_enum.pdf}
\vspace{-2em}
\caption{
IRE for RE $(\epsilon|a^{0,\infty})(a|\epsilon)^{0,3}$
and examples of PTs for string $a$.
S-norm is marked with $\#$.
}
\end{figure}

%\FloatBarrier

    \begin{Xdef}\label{tnorm_of_PTs}
    The \emph{p-norm} and \emph{s-norm} of a PT $t$ at position $p$ are:
    \begin{align*}
        \pnorm{t}{p} =
            \begin{cases}
                -1          &\text{if } p \in Pos(t) \text{ and } t|_p = \varnothing^i  \\[-0.2em]
                |str(t|_p)| &\text{if } p \in Pos(t) \text{ and } t|_p \neq \varnothing^i \\[-0.2em]
                \infty      &\text{if } p \not\in Pos(t)
            \end{cases}
    \quad\quad\quad
        \snorm{t}{p} =
            \begin{cases}
                -1          &\text{if } p \in Sub(t) \text{ and } t|_p = \varnothing^i  \\[-0.2em]
                |str(t|_p)| &\text{if } p \in Sub(t) \text{ and } t|_p \neq \varnothing^i \\[-0.2em]
                \infty      &\text{if } p \not\in Sub(t)
            \end{cases}
    \end{align*}
    \end{Xdef}

Generally the norm of a subtree means the number of alphabet symbols in its leaves, with two exceptions.
First, for nil subtrees the norm is $-1$: intuitively, they have the lowest ``ranking'' among all possible subtrees.
Second, for inexistent subtrees (those with positions not in $Pos(t)$) the norm is infinite.
This may seem counterintuitive at first, but it makes sense in the presense of REs with empty repetition.
According to the POSIX, optional empty repetitions are not allowed, and our definition reflects this:
if a tree $s$ has a subtree $s|_p$ corresponding to an empty repetition,
and another tree $t$ has no subtree at position $p$,
then the infinite norm $\|t\|_p$ ``outranks'' $\|s\|_p$.
We define two orders on PTs:

    \begin{Xdef}\label{total_order_on_PTs}
    \emph{P-order on PTs.}
    Given parse trees $t, s \in PT(e, w)$, we say that $t <_p s$ w.r.t. \emph{desision position} $p$
    iff $\pnorm{t}{p} > \pnorm{s}{p}$ and $\pnorm{t}{q} = \pnorm{s}{q} \; \forall q < p$.
    We say that $t < s$ iff $t <_p s$ for some $p$.
    \end{Xdef}

    \begin{Xdef}\label{partial_order_on_PTs}
    \emph{S-order on PTs.}
    Given parse trees $t, s \in PT(e, w)$, we say that $t \prec_p s$ w.r.t. \emph{desision position} $p$ % $p \in Sub(t) \cup Sub(s)$
    iff $\snorm{t}{p} > \snorm{s}{p}$ and $\snorm{t}{q} = \snorm{s}{q} \; \forall q < p$.
    We say that $t \prec s$ iff $t \prec_p s$ for some $p$.
    \end{Xdef}

    \begin{Xdef}\label{incomparable_IPTs}
    IPTs $t$ and $s$ are \emph{incomparable}, denoted $t \sim s$,
    iff neither $t \prec s$, nor $s \prec t$.
    \end{Xdef}

    \begin{XThe}\label{theorem_porder_on_PTs}
    P-order $<$ is a strict total order on IPTs.
    (Proof given in appendix [??].)
    \end{XThe}

    \begin{XThe}\label{theorem_sorder_on_PTs}
    S-order $\prec$ is a strict weak order on IPTs.
    (Proof given in appendix [??].)
    \end{XThe}

P-order is total --- the $<$-minimal tree is unique.
S-order is partial:
there might be two distinct PTs that coincide in all submatch positions, yet differ in some non-submatch positions.
Such trees are called \emph{incomparable},
and from disambiguation perspective they are indistinguishable.
%
Incomparability is an equivalence relation: it is
reflexive (obviously $s \sim s$),
symmetric (obviously $s \sim t$ implies $t \sim s$) and
transitive (see lemma \ref{lemma_ptorder_transitivity_of_incomparability} in appendix).
Consequently there is a whole class of $\prec$-minimal trees.
%$\PT_{min}(r,w) = \{ t \in \PT(r,w) \mid \forall u \in \PT(r,w) : t \sim u \vee t < u \}$.
%
One might ask, what is the relation between p-order $<$ and s-order $\prec$?
We show by the means of a counterexample that p-order is not an extension of s-order.
Consider trees $t$ and $u$ on figure \ref{fig_mark_enum}:
on one hand $t \prec_{2.2} u$, because $\snorm{t}{2.2} = \infty > 0 = \snorm{u}{2.2}$ and s-norms at all preceding submatch positions agree;
on the other hand $u <_{1.1} t$, because $\pnorm{t}{1.1} = -1 < 0 = \pnorm{u}{1.1}$
and p-norms at all preceding positions agree.
So the two orders may disagree.
However, as theorem \ref{theorem_order_compat} shows,
the two orders agree on the notion of minimal tree.
%
This is important, as it means that adding a few parentheses in RE will not drastically change submatch results:
we will continuously narrow down the class of $\prec$-minimal trees
until we are left with a unique $<$-minimal tree.
In the rest of the paper the words ``order'' and ``norm`` refer to s-order and s-norm.

    \begin{XThe}\label{theorem_order_compat}
    For an IRE $r$ and string $w$,
    let $t_{min}$ be the $<$-minimal tree in $\PT(r,w)$
    and let $T_{min} = \PT_{min}(r,w)$ be the class of the $\prec$-minimal trees in $\PT(r,w)$.
    Then $t_{min} \in T_{min}$.
    (Proof given in appendix [??].)
    \end{XThe}

Following the idea of Okui and Suzuki,
we go from comparison of parse trees to comparison of their linearized representation --- parenthesized expressions.
Parenthesis $\Xl$ is opening, and
parenthesis $\Xr$ is closing;
the \emph{nil}-parenthesis $\Xm$ is both opening and closing.
For convenience we sometimes annotate parentheses with \emph{height},
which we define as the number of preceding opening parentheses (including this one)
minus the number of preceding closing parentheses (including this one).
Explicit height annotations allow us to consider PE fragments in isolation
without losing the context of the whole expression.
However, height is not a part of parenthesis itself,
and it is not taken into account when comparing the elements of PEs.
Function $\Phi$ transforms PT at the given height into PE:

    \begin{align*}
    \Phi &: \YZ \times \XT_\Sigma \rightarrow \XP_\Sigma
    \\
    \Phi_{h}(t^{i}) &= \begin{cases}
        str(t^{i})                                            &\text{if } i = 0 \\[-0.2em]
        \Xm_h                                                 &\text{if } i \neq 0 \wedge t = \varnothing \\[-0.2em]
        \Xl_{h+1} \Xr_h                                       &\text{if } i \neq 0 \wedge t = \epsilon \\[-0.2em]
        \Xl_{h+1} a \Xr_h                                     &\text{if } i \neq 0 \wedge t = a \in \Sigma \\[-0.2em]
        \Xl_{h+1} \Phi_{h+1}(t_1) \dots \Phi_{h+1}(t_n) \Xr_h &\text{if } i \neq 0 \wedge t = T(t_1, \dots, t_n)
    \end{cases}
    \end{align*}
    \medskip

For a given RE $r$ and string $w$ the set of all PEs $\big\{ \Phi_{0}(t) \mid t \in PT(r, w) \big\}$ is denoted $\PE(r, w)$,
and the set of all prefixes in $\PE(r, w)$ is denoted $\PR(r, w)$.
Each PE $\alpha$ can be represented as $\alpha_0 a_1 \alpha_1 \dots a_n \alpha_n$,
where $\alpha_i$ is the $i$-th \emph{frame} --- a possibly empty sequence of parentheses between
subsequent alphabet symbols $a_i$ and $a_{i+1}$ (or the beginning and end of $\alpha$).
We say that PE prefixes $\alpha$ and $\beta$ are \emph{comparable}
if they contain the same number of frames and $\alpha, \beta \in \PR(r, w)$ for some $r$ and $w$.
%
For PE fragments $\alpha$ and $\beta$,
$\alpha \sqcap \beta$ denotes the longest common prefix of $\alpha$ and $\beta$,
$\alpha \backslash \beta$ denotes the suffix of $\alpha$ after removing $\alpha \sqcap \beta$,
$lasth(\alpha)$ denotes the height of the last parenthesis in $\alpha$ (or $\infty$ if $\alpha$ is empty or begins with a letter),
$minh(\alpha)$ denotes the minimal height of parenthesis in $\alpha$ (or $\infty$ if $\alpha$ is empty or begins with a letter),
$first(\alpha)$ denotes the first parenthesis in $\alpha$ (or $\bot$ if $\alpha$ is empty or begins with a letter).
For comparable PE fragments $\alpha$ and $\beta$ the index of the first distinct pair of frames is called \emph{fork}.

\begin{figure}\label{fig_pe}
\includegraphics[width=\linewidth]{img/pe.pdf}
\vspace{-2em}
\caption{
Examples: (a) -- (d): four main rules of POSIX comparison,
(e) -- pairwise comparison of PEs.
}
\end{figure}

%\FloatBarrier

    \begin{Xdef}
    Let $\alpha$, $\beta$ be comparable PE prefixes, such that
    $\alpha = \alpha_0 a_1 \alpha_1 \dots a_n \alpha_n$,
    $\beta = \beta_0 a_1 \beta_1 \dots a_n \beta_n$ and $k$ is the fork.
    We define $trace (\alpha, \beta)$ as the sequence $(\rho_0, \dots, \rho_n)$, where:
    $$
    \rho_i = \begin{cases}
        -1 &\text{if } i < k \\[-0.2em]
        min (lasth (\alpha_i \sqcap \beta_i), minh(\alpha_i \backslash \beta_i)) &\text{if } i = k \\[-0.2em]
        min (\rho_{i-1}, minh(\alpha_i)) &\text{if } i > k
    \end{cases}
    $$
    We write $traces(\alpha, \beta)$ to denote $\big( trace (\alpha, \beta), trace (\beta, \alpha) \big)$.
    \end{Xdef}

    \begin{Xdef}\label{prec1}
    Let $\alpha$, $\beta$ be comparable PE prefixes and
    $traces(\alpha, \beta) = \big( (\rho_0, \dots, \rho_n), (\rho'_0, \dots, \rho'_n) \big)$.
    The \emph{longest-precedence} relation $\sqsubset$ is defined as
    $\alpha \sqsubset \beta \Leftrightarrow \exists i \leq n:
        \big( \rho_i > \rho'_i \big) \wedge
        \big( \rho_j = \rho'_j \; \forall j > i \big)$.
    If neither $\alpha \sqsubset \beta$, nor $\beta \sqsubset \alpha$,
    then $\alpha$, $\beta$ are \emph{longest-equivalent}: $\alpha \sim \beta$
    (note that in this case $\rho_i = \rho'_i \; \forall i = \overline {1, n}$).
    \end{Xdef}

    \begin{Xdef}\label{prec2}
    Let $\alpha$, $\beta$ be comparable PE prefixes, and let
    $x = first (\alpha \backslash \beta)$,
    $y = first (\beta \backslash \alpha)$.
    The \emph{leftmost-precedence} relation $\subset$ is defined as
    $\alpha \subset \beta \Leftrightarrow x < y$, where
    the set of possible values of $x$ and $y$ is ordered as follows:
    $\bot < \Xr < \Xl < \Xm$.
    \end{Xdef}

    \begin{Xdef}\label{pe_order}
    The \emph{longest-leftmost-precedence} relation $<$ on comparable PE prefixes is defined as
    $\alpha < \beta \Leftrightarrow
        \big( \alpha \sqsubset \beta \big) \vee
        \big( \alpha \sim \beta \wedge \alpha \subset \beta \big)$.
    \end{Xdef}

    \begin{XThe}\label{theorem_order_on_pe_same_as_on_pt}
    Let $s, t \in PT(r, w)$, then
    $s <_p t \Leftrightarrow \Phi_{h}(s) < \Phi_{h}(t) \; \forall h$.
    (Proof in apendix [??].)
    \end{XThe}

Now we have a convenient definition of comparison on parenthesized expressions,
and theorem \ref{theorem_order_on_pe_same_as_on_pt} states that it is equivalent to comparison of parse trees.
What remains is to show that PEs can be compared \emph{incrementally}.
This is necessary for an efficient matching algorithm,
because otherwise we would need to accumulate full-length PEs before comparing them,
which means unbounded memory consumption --- PEs grow with the length of input.
Justification of incremental comparison consists of two parts.
First, lemma \ref{lemma_incr_cmp_frames} states that PEs can be compared frame by frame ---
this justifies the use of precedence tables.

    \begin{XLem}\label{lemma_incr_cmp_frames}
    \emph{Frame-by-frame comparison of PEs.}
    Let $\alpha = \alpha_0 a_1 \dots a_n \alpha_n$ and
    $\beta = \beta_0 a_1 \dots a_n \beta_n$ be comparable PE prefixes, where $n \geq 1$.
    If $\alpha_0 \dots \alpha_{n-1} < \beta_0 \dots \beta_{n-1}$,
    then $\alpha < \beta$.
    (Proof in apendix [??].)
    \end{XLem}

Second, in order to construct efficient $\epsilon$-closure algorithm
we need to show that PEs can be compared incrementally inside of each frame,
if the corresponding TNFA paths meet at an intermediate state.
This is necessary to avoid exploring potentially exponential number of paths in closure.
%
A \emph{path} in TNFA $(\Sigma, Q, T, \Delta, q_0, q_f)$
is a sequence of states $\{q_1, \hdots, q_n\} \subseteq Q$
connected by transitions $\{(q_i, a_i, b_i, q_{i + 1})\}_{i=1}^{n-1} \subseteq \Delta$, where $n \in \YN$.
%
Every path induces a string of alphabet symbols
and a mixed string of symbols and tags which corresponds to a fragment of PE
(positive opening tags map to $\Xl$, positive closing tags map to $\Xr$,
and every contiguous sequence of negative tags maps to $\Xm$).
We write $q_1 \overset {s|\alpha} {\rightsquigarrow} q_2$
to denote the fact that a path from $q_1$ to $q_2$ induces alphabet string $s$ and PE fragment $\alpha$.
%
We extend the notion of order from PEs to paths: given paths
$\pi_1 = q_1 \overset {s|\alpha} {\rightsquigarrow} q_2$ and
$\pi_2 = q_1 \overset {s|\beta} {\rightsquigarrow} q_3$
we say that $\pi_1 < \pi_2$ if $\alpha < \beta$.
%
For a given RE $r$ we say that a path is \emph{minimal} if it induces
$\alpha = \PE(t)$ for some minimal tree $t \in \PT(r)$.
%
Two paths are \emph{ambiguous} if their start and end states coincide and they induce the same alphabet string.
Two paths have a \emph{join point} if they have ambiguous prefixes.
%
%We state two facts that are later used to show that closure algorithm finds a minimal path.
%First, we show that minimal paths do not contain tagged $\epsilon$-loops (lemma \ref{lemma_closure_minpaths}).
%Second, we show that for paths without tagged $\epsilon$-loops
%comparison of path prefixes at the join point gives the same result as comparison of extended paths (lemma \ref{lemma_closure_rightdist}).
%In section \ref{section_closure} we give a specific closure algorithm and show that it discards paths with tagged $\epsilon$-loops.

\newcommand \lemmaclosureminpaths {
\emph{Paths with tagged $\epsilon$-loops are not minimal.}
    For any path $\pi_1 \pi_2 \pi_3$ where $\pi_2$ is a tagged $\epsilon$-loop
    there is path $\pi_1 \pi_3$
    such that $\pi_1 \pi_3 < \pi_1 \pi_2 \pi_3$.
}
\begin{XLem}\label{lemma_closure_minpaths}
\lemmaclosureminpaths
(Proof in apendix [??].)
\end{XLem}

\newcommand \lemmaclosurerightdist {
    \emph{Right distributivity of path comparison over path concatenation for paths with at most one tagged $\epsilon$-loop.}
    Let
    $\pi_\alpha = q_0 \overset {u | \alpha} {\rightsquigarrow} q_1$ and
    $\pi_\beta  = q_0 \overset {u | \beta}  {\rightsquigarrow} q_1$
    be ambiguous paths
    and $\pi_\gamma = q_1 \overset {\epsilon | \gamma} {\rightsquigarrow} q_2$
    their common $\epsilon$-suffix,
    such that paths $\pi_\alpha$ and $\pi_\beta$ are loop-free,
    at most one of $\pi_\alpha \pi_\gamma$ and $\pi_\beta \pi_\gamma$ contains a tagged $\epsilon$-loop.
    Then $\alpha < \beta \implies \alpha \gamma < \beta \gamma$.
}
\begin{XLem}\label{lemma_closure_rightdist}
\lemmaclosurerightdist
(Proof in apendix [??].)
\end{XLem}

%\vfill

\section{$\epsilon$-closure}\label{section_closure}

The problem of constructing $\epsilon$-closure with POSIX disambiguation
can be formulated as a shortest path problem on directed graph with weighted arcs.
%In our case \emph{weight} corresponds to PE fragment induced by the path.
%
Cormen [Cor??] gives a framework for shortest-path algorithms based on \emph{closed semirings}.
%
A \emph{semiring} is a structure $(\YK, \oplus, \otimes, \Xbar{0}, \Xbar{1})$, where
$\YK$ is a set,
$\oplus \!\!:\!\! \YK \times \YK \rightarrow \YK$ is an associative and commutative operation with identity element $\Xbar{0}$,
$\otimes \!\!:\!\! \YK \times \YK \rightarrow \YK$ is an associative operation with identity element $\Xbar{1}$,
$\otimes$ distributes over $\oplus$
and $\Xbar{0}$ is annihilator for $\otimes$.
%
Additionally, \emph{closed} semiring requires that
$\oplus$ is idempotent,
any countable $\oplus$-sum of $\YK$ elements is in $\YK$,
and associativity, commutativity, distributivity and idempotence apply to countable $\oplus$-sums.
Mohri [Moh02] generalizes this definition and notes that either left or right distributivity is sufficient.
%
In our case we have semiring $(\YP, min, \cdot, \varnothing, \epsilon)$, where
$\YP$ is the set of closure paths with at most one loop,
$min$ is POSIX comparison of ambiguous paths,
$\cdot$ is concatenation of paths (within TNFA bounds),
$\varnothing$ corresponds to an infinitely long path,
and $\epsilon$ is the empty path.
%
It is easy to show that
$min$ is commutative and associative (theorem \ref{theorem_order_on_pe_same_as_on_pt} and \ref{theorem_sorder_on_PTs}),
$min(\pi, \varnothing) = min(\varnothing, \pi) = \pi$,
$\cdot$ is associative, $\pi \cdot \epsilon = \epsilon \cdot \pi = \pi$,
$\pi \cdot \varnothing = \varnothing \cdot \pi = \varnothing$,
and right distributivity of $\cdot$ over $min$ for paths with at most one $\epsilon$-loop is given by lemma \ref{lemma_closure_rightdist}.
%
Idempotence holds because $min(\pi, \pi) = \pi$.
%
Since $\YP$ is limited to paths with at most one $\epsilon$-loop,
countable subsets of $\YP$ are finite
and the properties for $\oplus$-sums over countable subsets are satisfied.
\\

\begin{algorithm}[] \DontPrintSemicolon \SetKwProg{Fn}{}{}{} \SetAlgoInsideSkip{medskip}
\begin{multicols}{2}

    \newcommand \NOPASS {O\!F\!F}
    \newcommand \TOPSORT {T\!O\!P}
    \newcommand \LINEAR {L\!I\!N}
    \newcommand \INQUEUE {I\!N}
    \newcommand \OFFQUEUE {OUT}
    \newcommand \Xfalse {f\!al\!se}

    \setstretch{0.85}

    \Fn {$\underline{closure \Xund gor1(N\!=\!(\Sigma, Q, T, \Delta, q_0, q_f), X, U, B, D)} \smallskip$} {

        \Indm
        context: $C = (N, U, B, D$ \;
        \Indp
        $,\, topsort, linear : \text{stacks of states } q \in Q$ \;
        $,\, result  : Q \rightarrow \YC \cup \{ \varnothing \}$   \;
        $,\, status  : Q \rightarrow \{ \NOPASS, \TOPSORT, \LINEAR \}$ \;
        $,\, indeg   : Q \rightarrow \YZ$                          \tcp{in-degree of state}
        $,\, active  : Q \rightarrow \YB$                          \tcp{true if state needs rescan}
        $,\, etrans  : Q \rightarrow 2^{\Delta^\epsilon}$          \tcp{$\epsilon$-transitions ordered by priority}
        $,\, next    : Q \rightarrow \YZ)$                         \tcp{index of current transition}
        \Indm
        \Indp

        \BlankLine
        $result(q) \equiv \varnothing$ \;
        $status(q) \equiv \NOPASS$ \;
        $active(q) \equiv \Xfalse$ \;
        $next(q)   \equiv 1$ \;

        \BlankLine
        \For {$x = (\Xund, q, \Xund, \Xund) \in X$ sorted by inverted $prec(\,)$} {
            $result(q) = x$ \;
            $push(topsort, q)$
        }

        \BlankLine
        \While {$topsort$ is not empty} {

            \BlankLine
            \While {$topsort$ is not empty} {
                $q = pop(topsort)$ \;

                \If {$status(q) \neq \LINEAR$} {

                    $status(q) = \TOPSORT$ \;
                    $push(topsort, q)$ \;

                    \BlankLine
                    \If {$\neg scan(q, C, \Xfalse)$} {
                        $status(q) = \LINEAR$ \;
                        $pop(topsort)$ \;
                        $push(linear, q)$
                    }
                }
            }

            \BlankLine
            \While {$linear$ is not empty} {
                $q = pop(linear)$ \;

                \If {$active(q)$} {
                    $next(q) = 1$ \;
                    $active(q) = \Xfalse$ \;
                    $scan(q, C, true)$ \;
                }

                $status(q) = \NOPASS$ \;
            }
        }

        \BlankLine
        \Return $prune(result, N)$
    }
    \BlankLine
    \BlankLine

    \Fn {$\underline{scan (q, C, all)} \smallskip$} {
        $any = \Xfalse$ \;

        \While {$next(q) < n$} {
            $(q, \epsilon, \tau, p) = etrans (q)_{next(q)}$ \;
            $next(q) = next(q) + 1$ \;
            $x = result(p), \; (o, q, u, r) = result(q)$ \;
            $y = (o, p, extend \Xund path (H, u, \tau), r)$ \;

            \BlankLine
            \If {$x \!=\! \varnothing \vee indeg(p) \!<\! 2 \vee less(y, x, C)$} {
                $result(p) = y$ \;
                \If {$status(q) = \NOPASS$} {
                    $any = true$ \;
                    $next(p) = 1$ \;
                    $push(topsort, p)$ \;
                    \lIf {$\neg all$} {$break$}
                }
                \lElse {
                    $active(p) = 1$
                }
            }
        }

        \Return $any$ \;
    }
    \BlankLine
    \BlankLine

\columnbreak

    \Fn {$\underline{closure \Xund gtop(N\!=\!(\Sigma, Q, T, \Delta, q_0, q_f), X, U, B, D)} \smallskip$} {

        \Indm
        context: $C = (N, U, B, D$ \;
        \Indp
        $,\, queue : \text{priority queue of states } q \in Q$ \;
        $,\, result  : Q \rightarrow \YC \cup \{ \varnothing \}$   \;
        $,\, status  : Q \rightarrow \{ \INQUEUE, \OFFQUEUE\}$     \;
        $,\, indeg   : Q \rightarrow \YZ$                          \tcp{in-degree of state}
        $,\, topord  : Q \rightarrow \YZ$                          \tcp{topological index of state}
        $,\, etrans  : Q \rightarrow 2^{\Delta^\epsilon}$          \tcp{$\epsilon$-transitions}
        \Indm
        \Indp

        \BlankLine
        $result(q) \equiv \varnothing$ \;
        $status(q) \equiv \OFFQUEUE$ \;

        \BlankLine
        \For {$x = (\Xund, q, \Xund, \Xund) \in X$} {
            $y = result(q)$ \;
            \If {$y \!=\! \bot \vee less(x, y, C)$} {
                $result(q) = x$ \;
                \If {$status(q) \neq \INQUEUE$} {
                    $insert \Xund with \Xund priority(queue, q, topord(q))$ \;
                    $status(q) = \INQUEUE$ \;
                }
            }
        }

        \BlankLine
        \While {$queue$ is not empty} {

            $q = extract \Xund min(queue)$ \;
            $status(q) = \OFFQUEUE$ \;

            \BlankLine
            \For {$(q, \epsilon, \tau, p) \in etrans (q)$} {
                $x = result(p), \; (o, q, u, r) = result(q)$ \;
                $y = (o, p, extend \Xund path (H, u, \tau), r)$ \;

                \BlankLine
                \If {$x \!=\! \varnothing \vee indeg(p) \!<\! 2 \vee less(y, x, C)$} {
                    $result(p) = y$ \;
                    \If {$status(p) \neq \INQUEUE$} {
                        $insert \Xund with \Xund priority(queue, p, topord(p))$ \;
                        $status(p) = \INQUEUE$ \;
                    }
                }
            }
        }

        \BlankLine
        \Return $prune(result, N)$
    }
    \BlankLine
    \BlankLine

    \Fn {$\underline{prune (X, N)} \smallskip$} {
        \Return $\big\{ (\Xund, q, \Xund, \Xund) \in X \mid
            q \in F \vee \exists (q, \alpha, \Xund, \Xund) \in \Delta^\Sigma \}$
    }
    \BlankLine
    \BlankLine

    \Fn {$\underline{less (x, y, C)} \smallskip$} {
        $(\Xund, \Xund, l) = compare (x, y, U, B, D)$ \;
        \Return $l < 0$
    }
    \BlankLine
    \BlankLine

    \Fn {$\underline{prec (x, y, D)} \smallskip$} {
        $(q, \Xund, \Xund, \Xund) = x, \; (p, \Xund, \Xund, \Xund) = y$ \;
        \Return $D[q][p] < 0$
    }
    \BlankLine
    \BlankLine

\end{multicols}
\vspace{1em}
\caption{
Closure algorithms GOR1 (on the left) and GTOP (on the right).
Definition of functions of $push()$, $pop()$, $insert \Xund with \Xund priority()$, $extract \Xund min()$,
$indeg()$ and $topord()$ is omitted for brevity.
Definitions of $compare ()$ and $extend \Xund path ()$ are given in sections \ref{section_comparison} and \ref{section_pathtree}.
$\YC$ is the set of all configurations.}
\end{algorithm}

We give two algorithms for closure construction: GOR1, named after the well-known Goldberg-Radzik algorithm [GRC??],
and GTOP, named after ``global topological order''.
%
Both have the usual structure of shortest-path finding algorithms.
The algorithm starts with a set of initial configurations, empty queue and empty set of resulting configurations.
Initial configurations are enqueued and the algorithm loops until the queue becomes empty.
At each iteration it dequeues configuration $(q, o, u, r)$ and scans $\epsilon$-transitions from state $q$.
For transition $(q, \Xund, \gamma, p)$ it constructs a new configuration $(p, o, v, r)$
that combines $u$ and $\gamma$ in an extended path $v$.
If the resulting set contains another configuration for state $p$,
then the algorithm choses configuration which has a better path from POSIX perspective.
Otherwise it adds the new configuration to the resulting set.
If the resulting set was changed, the new configuration is enqueued for further scanning.
Eventually all states in $\epsilon$-closure are explored, no improvements can be made, and the algorithm terminates.
\\

Importantly, the algorithm finds non-looping paths before looping ones.
Given that, and using lemma \ref{lemma_closure_minpaths},
we can show by induction on path length that the paths constructed at each step of the algorithm do not contain $\epsilon$-loops.
This means that for any two paths explored by the algorithm,
at most one path may contain tagged $\epsilon$-loop (and only one loop),
which justifies the application of lemma \ref{lemma_closure_rightdist}.
%
(Note that for paths with multiple $\epsilon$-loops right distributivity may not hold:
we may have paths
$\pi_\alpha = q_0 \overset {u | \alpha} {\rightsquigarrow} q_1$,
$\pi_\beta = q_1 \overset {\epsilon | \beta}  {\rightsquigarrow} q_1$ and
$\pi_\gamma = q_1 \overset {\epsilon | \gamma}  {\rightsquigarrow} q_1$,
such that $\pi_\beta$ and $\pi_\gamma$ are two different $\epsilon$-loops through the same subautomaton
and $\pi_\alpha \pi_\beta < \pi_\alpha \pi_\gamma$:
in this case $\pi_\alpha \pi_\beta \pi_\gamma < \pi_\alpha \pi_\gamma$,
but $\pi_\alpha \pi_\beta > \pi_\alpha$, because the first is a proper prefix of the second.)
%
Lemma \ref{lemma_closure_rightdist} allows us to skip comparison in non-join states (with in-degree 1), because
any path to such state is formed by concatenation of the unique transition and the shortest known path to the previous state.
\\

The difference between GOR1 and GTOP is in the order they inspect configurations.
%
Both algorithms are based on the idea of topologcal ordering.
Unlike other shortest-path algorithms, their queuing discipline is based on graph structure, not on the distance estimates.
This is crucial, because we do not have any distance estimates:
paths can be compared, but there is no absolute ``POSIX-ness'' value that we can attribute to each path.
%
GOR1 is described in [CGR93].
It uses two stacks and makes a number of passes;
each pass consists of a depth-first search on admissible subgraph
followed by a linear scan of states that are topologically ordered by depth-first search.
The algorithm is one of the most efficient shortest-path algorithms [CGR96] [CGR99].
$n$-Pass structure guarantees worst-case complexity $O(n \, m)$ of the Bellman-Ford algorithm,
where $n$ is the number of states and $m$ is the number of transitions in $\epsilon$-closure
(both can be approximated by TNFA size).
%
GTOP is a simple algorithm that maintains one global priority queue (e.g. a binary heap)
ordered by the topological index of states (for graphs with cycles, we assume reverse depth-first post-order).
Since GTOP does not have $n$-pass structure, its worst-case complexity is not clear.
However, it is much simpler to implement
and in practice it performs almost identically to GOR1 on graphs induced by TNFA $\epsilon$-closures.
%
On acyclic graphs, both GOR1 and GTOP have linear $O(n + m)$ complexity.


\section{Tree representation of paths}\label{section_pathtree}

In this section we specify the representation of path fragments in configurations
and define path context $U$ and functions $empty \Xund path ()$ and $extend \Xund path ()$
used in previous sections.
%
An obvious way to represent tagged path is to use a sequence of tags, such as a list or an array:
in that case $empty \Xund path ()$ can be implemented as an empty sequence,
and $extend \Xund path ()$ is just an append operation.
%
However, a more efficient representation is possible
if we consider the structure formed by paths in $\epsilon$-closure.
This structure is a \emph{prefix tree} of tags.
Some care is necessary with TNFA construction in order to ensure prefixness,
but that is easy to accommodate and we give the details in section \ref{section_tnfa}.
Storing paths in a prefix tree achieves two purposes:
first, we save on the duplicated prefixes,
and second, copying paths becomes as simple as copying a pointer to a tree leaf --- no need to copy the full sequence.
This technique was used by many researches, e.g. Laurikari mentions a \emph{functional data structure} in [Lau01]
and Karper describes it as the \emph{flyweight pattern} [Kar15].
\\

A convenient represention of tag tree is an indexed sequence of nodes.
Each node is a triple $(p, s, t)$ where
$p$ is the index of predecessor node,
$s$ is a set of indices of successor nodes
and $t$ is a tag (positive or negative).
%
Forward links are only necessary if the advanced algorithm for $update \Xund ptables ()$ is used
(section \ref{section_comparison}), otherwise successor component can be omitted.
%
Now we can represent $u$-components of configurations with indices in the $U$-tree:
root index is $0$ (which corresponds to the empty path),
and each $u$-component is a tree index from which we can trace predecessors to the root
(function $unroll \Xund path ()$ demonstrates this).
%
In the implementation, it is important to use numeric indices rather than pointers
because it allows to use the ``two-fingers'' algorithm to find fork of two paths (section \ref{section_comparison}).
%
We assume the existence of functions
$pred(U, n)$ that returns $p$-component of $n$-th node,
$succ(U, n)$ that returns $s$-component of $n$-th node and
$tag(U, n)$ that returns $t$-component of $n$-th node.
\\

\begin{algorithm}[H] \DontPrintSemicolon \SetKwProg{Fn}{}{}{} \SetAlgoInsideSkip{medskip}
\begin{multicols}{2}
    \setstretch{0.8}

    \Fn {$\underline {empty \Xund path (\,)} \smallskip$} {
        \Return $0$ \;
    }
    \BlankLine

    \Fn {$\underline {extend \Xund path (U, n, \tau)} \smallskip$} {
        \If {$\tau \neq \epsilon$} {
            $m = |U| + 1$ \;
            append $m$ to $succ(U, n)$ \;
            append $(n, \emptyset, \tau)$ to $U$ \;
            \Return $m$ \;
        }
        \lElse {
            \Return $n$
        }
    }
    \BlankLine

    \vfill

\columnbreak

    \Fn {$\underline {unroll \Xund path (U, n)} \smallskip$} {
        $u = \epsilon$ \;
        \While { $n \neq 0$ } {
            $u = u \cdot tag(U, n)$ \;
            $n = pred(U, n)$ \;
        }
        \Return $reverse(u)$ \;
    }
    \BlankLine

    \vfill

\end{multicols}
\vspace{1em}
\caption{Operations on tag tree.}
\end{algorithm}
\medskip


\section{Representation of match results}\label{section_results}

In this section we show two ways to construct match results: POSIX offsets and a parse tree.
%
In the first case, $r$-component of configurations is an array of offset pairs $pmatch$.
Offsets are updated incrementally at each step by scanning the corresponding path fragment
and setting negative tags to $-1$ and positive tags to the current step number.
We need the most recent value of each tag, therefore we take care to update tags at most once.
Negative tags allow us to skip initialization of offsets.
Helper function $sub(T, t)$ maps each tag to the corresponding submatch group
(it returns the second component $k$ for $(t, k) \in T$).
%
In the second case, $r$-component of configurations is a tagged string that is accumulated at each step,
and eventually converted to a parse tree at the end of match.
The resulting parse tree is only partially structured:
leaves that correspond to subexpressions with zero implicit submatch index contain ``flattened'' substring of alphabet symbols.
It is possible to construct parse trees incrementally as well,
but this is more complex and the partial trees may require even more space than tagged strings.
%
\\

\begin{algorithm}[H] \DontPrintSemicolon \SetKwProg{Fn}{}{}{}
\begin{multicols}{2}
    \setstretch{0.8}

    \Fn {$\underline{initial \Xund result (T)} \smallskip$} {
        $n = max \{ sub(T, t) \mid t \in \YN \}$ \;
        \Return uninitialized $n$-array of pairs $(rm \Xund so, rm \Xund eo)$\;
    }
    \BlankLine
    \BlankLine

    \Fn {$\underline{update \Xund result (T, X, U, k, \Xund)} \smallskip$} {
        \Return $\big\{ (q, o, u, set \Xund tags (T, U, u, r, k))$ \;
        \Indp\Indp\Indp\Indp\Indp\Indp\Indp\Indp $\mid (q, o, u, r) \in X \big\}$ \; \Indm\Indm\Indm\Indm\Indm\Indm\Indm\Indm
    }
    \BlankLine
    \BlankLine

    \Fn {$\underline{f\!inal \Xund result (T, U, u, r, k)} \smallskip$} {
        $pmatch = set \Xund tags (T, U, u, r, k)$ \;
        $pmatch[0].rm \Xund so = 0$ \;
        $pmatch[0].rm \Xund eo = k$ \;
        \Return $pmatch$ \;
    }
    \BlankLine
    \BlankLine

    \Fn {$\underline{set \Xund tags (T, U, n, pmatch, k)} \smallskip$} {
        $done(\Xund) \equiv f\!alse$ \;
        \While {$n \neq 0$} {
            $t = tag(U, n), \; s = sub(T, |t|)$ \;
            \If {$s \neq 0 \wedge \neg done(s)$} {
                $done(s) = true$ \;
                \lIf {$t < 0$} {$l = -1$}
                \lElse {$l = k$}
                \lIf {$t \, mod \, 2 \equiv 1$} {$pmatch[s].rm \Xund so = l$}
                \lElse {$pmatch[s].rm \Xund eo = l$}
            }
            $n = pred(U, n)$ \;
        }
        \Return $pmatch$ \;
    }
    \BlankLine

    \vfill

\columnbreak

    \Fn {$\underline{initial \Xund result (\Xund)} \smallskip$} {
        \Return $\epsilon$ \;
    }
    \BlankLine
    \BlankLine

    \Fn {$\underline{update \Xund result (\Xund, X, U, \Xund, \alpha)} \smallskip$} {
        \Return $\big\{ (q, o, u, r \cdot unroll \Xund path (U, u) \cdot \alpha)$ \;
        \Indp\Indp\Indp\Indp\Indp\Indp\Indp\Indp $\mid (q, o, u, r) \in X \big\}$ \; \Indm\Indm\Indm\Indm\Indm\Indm\Indm\Indm
    }
    \BlankLine
    \BlankLine

    \Fn {$\underline{f\!inal \Xund result (\Xund, U, u, r, \Xund)} \smallskip$} {
        \Return $parse \Xund tree (r \cdot unroll \Xund path (U, u), 1)$ \;
    }
    \BlankLine
    \BlankLine

    \Fn {$\underline{parse \Xund tree (u, i)} \smallskip$} {
        \If {$u = (2i \!-\! 1) \cdot (2i)$} {
            \Return $T^i(\epsilon)$
        }
        \If {$u = (1 \!-\! 2i) \cdot \hdots $} {
            \Return $T^i(\varnothing)$
        }
        \If {$u = (2i \!-\! 1) \cdot \alpha_1 \hdots \alpha_n \cdot (2i) \wedge \alpha_1, \hdots, \alpha_n \in \Sigma $} {
            \Return $T^i(a_1, \hdots, a_n)$
        }
        \If {$u = (2i \!-\! 1) \cdot \beta_1 \hdots \beta_m \cdot (2i) \wedge \beta_1 = 2j \!-\! 1 \in T$} {
            $n = 0, k = 1$ \;
            \While {$k \leq m$} {
                $l = k$ \;
                \lWhile {$|\beta_{k+1}| > 2j$} {
                    $k = k + 1$
                }
                $n = n + 1$ \;
                $t_n = parse \Xund tree (\beta_l \dots \beta_k, j)$
            }
            \Return $T^i(t_1, \dots, t_n)$
        }
        \Return $\varnothing$ \tcp{ill-formed PE}
    }
    \BlankLine

    \vfill

\end{multicols}
\vspace{1.5em}
\caption{Construction of match results: POSIX offsets (on the left) and parse tree (on the right).}
\end{algorithm}
\medskip


\section{Disambiguation procedures}\label{section_comparison}

In this section we define disambiguation procedures $compare ()$ and $update \Xund ptables ()$.
The pseudocode follows definition \ref{pe_order} closely
and relies on the prefix tree representation of paths given in section \ref{section_results}.
%
In order to find fork of two paths in $compare ()$ we use so-called ``two-fingers'' algorithm,
which is based on the observation that parent index is always less than child index.
Given two indices $n_1$ and $n_2$, we continuously set the greater index to its parent until the indices become equal,
at which point we have either found fork or the root of $U$-tree.
We track minimal height of each path along the way
and memorize the pair of indices right after the fork --- they are used to determine the leftmost path in case of equal heights.
%
We assume the existence of helper function $height(T, t)$ that maps each tag to its height.
\\

\begin{algorithm}[H] \DontPrintSemicolon \SetKwProg{Fn}{}{}{} \SetAlgoInsideSkip{medskip}
\begin{multicols}{2}
    \setstretch{0.8}

    \Fn {$\underline {compare (c_1, c_2, U, B, D)} \smallskip$} {
        $(\Xund, o_1, n_1, \Xund) = c_1, \; (\Xund, o_2, n_2, \Xund) = c_2$ \;

        \lIf { $o_1 = o_2 \wedge n_1 = n_2$ } {
            \Return $(\infty, \infty, 0)$
        }

        \BlankLine
        $f\!ork = o_1 = o_2$ \;
        \lIf {$f\!ork$ } {
            $h_1 = h_2 = \infty$
        }
        \lElse {
            $h_1 = B[o_1][o_2], \; h_2 = B[o_2][o_1]$
        }

        \BlankLine
        $m_1 = m_2 = \bot$ \;
        \While {$n_1 \neq n_2$} {
            \If {$n_1 > n_2$} {
                $h_1 = min(h_1, height(T, tag(U, n_1)))$ \;
                $m_1 = n_1, \; n_1 = pred(U, n_1)$ \;
            }
            \Else {
                $h_2 = min(h_2, height(T, tag(U, n_2)))$ \;
                $m_2 = n_2, \; n_2 = pred(U, n_2)$ \;
            }
        }
        \If {$n_1 \neq \bot$} {
            $h = height(T, tag(U, n_1))$ \;
            $h_1 = min(h_1, h), \; h_2 = min(h_2, h)$ \;
        }

        \BlankLine
        \lIf     {$h_1 > h_2$}    {$l = -1$}
        \lElseIf {$h_1 < h_2$}    {$l = 1$ }
        \lElseIf {$\neg f\!ork$}  {$l = D[o_1][o_2]$}
        \lElse                    {$l = le\!f\!tprec(m_1, m_2, U)$}

        \BlankLine
        \Return $(h_1, h_2, l)$ \;
    }
    \BlankLine
    \BlankLine

    \Fn {$\underline {le\!f\!tprec (n_1, n_2, U)} \smallskip$} {

        \lIf {$n_1 = n_2$} { \Return $0$ }
        \lIf {$n_1 = \bot$} { \Return $-1$ }
        \lIf {$n_2 = \bot$} { \Return $1$ }

        \BlankLine
        $t_1 = tag(U, n_1), \; t_2 = tag(U, n_2)$ \;

        \BlankLine
        \lIf {$t_1 mod \, 2 \equiv 0$} { \Return $-1$ }
        \lIf {$t_2 mod \, 2 \equiv 0$} { \Return $1$ }

        \BlankLine
        \lIf {$t_1 < 0$} { \Return $1$ }
        \lIf {$t_2 < 0$} { \Return $-1$ }

        \BlankLine
        \Return $0$
    }
    \BlankLine
    \BlankLine

    \Fn {$\underline {update \Xund ptables (N, X, U, B, D)} \smallskip$} {
        \For {$x_1 = (q_1, \Xund, \Xund, \Xund) \in X$} {
            \For {$x_2 = (q_2, \Xund, \Xund, \Xund) \in X$} {
                $(h_1, h_2, l) = compare (x_1, x_2, U, B, D)$ \;
                $B' [q_1] [q_2] = h_1, \; D' [q_1] [q_2] = l$ \;
                $B' [q_2] [q_1] = h_2, \; D' [q_2] [q_1] = -l$
            }
        }
        \BlankLine
        \Return $(B', D')$ \;
    }

    \vfill
    \columnbreak

    \Fn {$\underline {update \Xund ptables (N, X, U, B, D)} \smallskip$} {
        $i = 0, \; next(n) \equiv 1, \; \text{empty stack } S, \; \text{empty array } L$ \;
        $push(S, 0)$ \;

        \BlankLine
        \While {$S$ is not empty} {
            $n = pop(S)$ \;

            \BlankLine
            \If {$next(n) < k$} {
                $push(S, n)$ \;
                $push(S, succ(U, n)_{next(n)})$ \;
                $next(n) = next(n) + 1$ \;
                $continue$ \;
            }

            \BlankLine
            $h = height(T, tag(U, n)), \; i_1 = i$ \;

            \BlankLine
            \For {$(q, o, n_1, \Xund) \in X \mid n_1 = n$} {
                $i = i + 1, \; L[i] = (q, o, \bot, h)$ \;
            }
            \For {$j_1 = \overline{i_1 + 1, i}$} {
                \For {$j_2 = \overline{j_1, i}$} {
                    $(q_1, o_1, \Xund, \Xund) = L[j_1]$ \;
                    $(q_2, o_2, \Xund, \Xund) = L[j_2]$ \;

                    \BlankLine
                    \If {$n = 0 \wedge o_1 \neq o_2$} {
                        $h_1 = B[o_1][o_2], \; h_2 = B[o_2][o_1]$ \;
                        $l = D[o_1][o_2]$ \;
                    }
                    \lElse {
                        $h_1 = h_2 = h, \; l = 0$
                    }

                    \BlankLine
                    $B'[q_1][q_2] = h_1, \; D'[q_1][q_2] = l$ \;
                    $B'[q_2][q_1] = h_2, \; D'[q_2][q_1] = -l$ \;
                }
            }

            \BlankLine
            \For {$m \in succ(U, n)$ in reverse} {
                $i_2 = i_1$ \;
                \lWhile {$i_2 > 0 \wedge L[i_2].n = m$} {
                    $i_2 = i_2 - 1$
                }

                \BlankLine
                \For {$j_1 = \overline{i_2, i_1}$} {
                    $L[j_1].h = min(L[j_1].h, h)$; \;

                    \BlankLine
                    \For {$j_2 = \overline{i_1, i}$} {
                        $(q_1, o_1, n_1, h_1) = L[j_1]$ \;
                        $(q_2, o_2, n_2, h_2) = L[j_2]$ \;

                        \BlankLine
                        \If {$n = 0 \wedge o_1 \neq o_2$} {
                            $h_1 = min(h_1, B[o_1][o_2])$ \;
                            $h_2 = min(h_2, B[o_2][o_1])$ \;
                        }

                        \BlankLine
                        \lIf     {$h_1 > h_2$}    {$l = -1$}
                        \lElseIf {$h_1 < h_2$}    {$l = 1$ }
                        \lElseIf {$o_1 \neq o_2$} {$l = D[o_1][o_2]$}
                        \lElse                    {$l = le\!f\!tprec(n_1, n_2, U)$}
                    }

                    \BlankLine
                    $B'[q_1][q_2] = h_1, \; D'[q_1][q_2] = l$ \;
                    $B'[q_2][q_1] = h_2, \; D'[q_2][q_1] = -l$ \;
                }

                $i_1 = i_2$ \;
            }

            \BlankLine
            \lFor {$j = \overline{i_1, i}$} {
                $L[j].n = n$
            }
        }

        \BlankLine
        \Return $(B', D')$ \;
    }

\end{multicols}
%\vspace{1em}
\caption{Disambiguation procedures.}
\end{algorithm}
\medskip

We give two alternative algorithms for $update \Xund ptables ()$:
a simple one with $O(m^2 \, t)$ complexity (on the left) and a complex one with $O(m^2)$ complexity (on the right).
Worst case is demonstrated by RE $((a|\epsilon)^{0,k})^{0,\infty}$ where $n \in \YN$,
for which the simple algorithm takes $O(k^3)$ time and the complex algorithm takes $O(k^2)$ time.
%
The idea of complex algorithm is to avoid repeated rescanning of path prefixes in the $U$-tree.
It makes one pass over the tree,
constructing an array $L$ of \emph{level items} $(q, o, u, h)$, where
$q$ and $o$ are state and origin as in configurations,
$u$ is the current tree index and $h$ is the current minimal height.
One item is added per each closure configuration $(q, o, u, r)$ when traversal reaches tree node with index $u$.
After a subtree has been traversed,
the algorithm scans level items added during traversal of this subtree (such items are distinguished by their $u$-component),
sets their $h$-component to the minimum of $h$ and the height of tag at the current node,
and computes the new value of $B$ and $D$ matrices for each pair of $q$-states in items from different branches.
After that, $u$-component of all scanned items is downgraded to the tree index of current node
(erasing the difference between items from different branches).


\section{Lazy disambiguation}\label{section_lazy}

Most of the overhead in our algorithm comes from updating $B$ and $D$ matrices at each step.
It is all the more unfortunate since many comparisons performed by $update \Xund ptables ()$ are useless ---
the compared paths may never meet.
In fact, if the input is unambiguous, all comparisons are useless.
%
A natural idea, therefore, is to compare paths only in case of real ambiguity (when they meet in closure)
and avoid computation of precedence matrices altogether.
%
We can do it with a few modifications to our original algorithm.
%
First, we no longer need $B$ and $D$ matrices and $update \Xund ptables ()$ function.
Instead, we introduce cache $C$ that maps a pair of tree indices $(n_1, n_2)$ to a triple of precedence values $(h_1, h_2, l)$.
Cache stores the ``useful'' part of $B$ and $D$ matrices on multiple preceding steps.
It is populated lazily during disambiguation
and allows us to avoid re-computing the same values multiple times.
%
Second, we need to modify tree representation of paths in the following way:
forward links are no longer needed (parent links are sufficient),
and tree nodes must be augmented with information about current step and origin state (we assume the existence of helper functions $step()$ and $origin()$).
%
Third, instead of using $empty \Xund path ()$ to initialize path fragments in configurations
we need to set them to path fragments of their parent configurations,
so that paths are accumulated rather than reset at each step.
%
Fourth, we no longer need to call $update \Xund result ()$ at each step --- this can be done once at the end of match.
%
Below is the modified lazy version of $compare()$, the only part of the algorithm that requires non-trivial change.
\\

\iffalse
\begin{itemize}[itemsep=0.5em]
    \item Remove $B$ and $D$ matrices and $update \Xund ptables ()$.

    \item Modify tree representation of paths in the following way:
        remove forward links (only parent links are needed)
        and extend tree nodes with information about current step and origin state.

    \item Instead of initializing path fragments in configurations with $empty \Xund path ()$,
        initialize them with path fragments of the parent configuration
        (so that paths are accumulated rather than reset at each step).

    \item Add a cache that maps a pair of tree indices $(n_1, n_2)$ to a triple of already computed precedence values $(h_1, h_2, l)$.

    \item Modify $compare ()$ in the following way:

    \item Instead of calling $update \Xund result ()$ at each step, do it once at the end of match.
    \\
\end{itemize}
\fi

\begin{algorithm}[H] \DontPrintSemicolon \SetKwProg{Fn}{}{}{} \SetAlgoInsideSkip{medskip}
\begin{multicols}{2}
    \setstretch{0.8}

    \Fn {$\underline {compare (c_1, c_2, U, C)} \smallskip$} {
        $(\Xund, \Xund, n_1, \Xund) = c_1, \; (\Xund, \Xund, n_2, \Xund) = c_2$ \;

        \BlankLine
        \Return $compare1 (n_1, n_2, U, C)$ \;
    }
    \BlankLine
    \BlankLine

    \Fn {$\underline {compare1 (n_1, n_2, U, C)} \smallskip$} {
        \If {$C(n_1, n_2) = \varnothing $} {
            $C(n_1, n_2) = compare2 (n_1, n_2, U, C)$ \;
        }

        \BlankLine
        \Return $C(n_1, n_2)$ \;
    }
    \BlankLine
    \BlankLine

    \vfill
    \columnbreak

    \Fn {$\underline {compare2 (n_1, n_2, U, C)} \smallskip$} {
        \lIf { $n_1 = n_2$ } {
            \Return $(\infty, \infty, 0)$
        }

        \BlankLine
        $h_1 = h_2 = \infty$ \;
        $o_1 = origin(U, n_1), \; o_2 = origin(U, n_2)$ \;
        $s_1 = step(U, n_1), \; s_2 = step(U, n_2), \; s = max (s_1, s_2)$ \;
        $f\!ork = o_1 = o_2 \wedge s_1 = s_2$ \;

        \BlankLine
        $m_1 = m_2 = \bot$ \;
        \While {$n_1 \neq n_2 \wedge (s_1 \geq s \vee s_2 \geq s)$} {
            \If {$s_1 \geq s \wedge (n_1 > n_2 \vee s_2 < s)$} {
                $h_1 = min(h_1, height(T, tag(U, n_1)))$ \;
                $m_1 = n_1, \; n_1 = pred(U, n_1), \; s_1 = step(U, n_1)$ \;
            }
            \Else {
                $h_2 = min(h_2, height(T, tag(U, n_2)))$ \;
                $m_2 = n_2, \; n_2 = pred(U, n_2), \; s_2 = step(U, n_2)$ \;
            }
        }

        \BlankLine
        \If {$\neg f\!ork$ } {
            $(h'_1, h'_2, l) = compare1(n_1, n_2, U, C)$ \;
            $h_1 = min(h_1, h'_1), \; h_2 = min(h_2, h'_2)$ \;
        }
        \ElseIf {$n_1 \neq \bot$} {
            $h = height(T, tag(U, n_1))$ \;
            $h_1 = min(h_1, h), \; h_2 = min(h_2, h)$ \;
        }

        \BlankLine
        \lIf     {$h_1 > h_2$} {$l = -1$}
        \lElseIf {$h_1 < h_2$} {$l = 1$ }
        \lElseIf {$f\!ork$}    {$l = le\!f\!tprec(m_1, m_2, U)$}

        \BlankLine
        \Return $(h_1, h_2, l)$ \;
    }
    \BlankLine
    \BlankLine

\end{multicols}
\vspace{1em}
\caption{Lazy disambiguation procedures (we assume that cache $C$ is modified in-place).}
\end{algorithm}
\medskip


The problem with this approach is that we need to keep full-length history of each active path:
at the point of ambiguity we may need to look an arbitrary number of steps back
in order to find the fork of ambiguous paths.
%
This may be acceptable for small inputs (and memory footprint may even be smaller due to reduction of precedence matrices),
but it is definitely infeasible for very long or streaming inputs.
%
A possible solution may be a hybrid approach that uses lazy disambiguation,
but every $k$ steps fully calculates precedence matrices and ``forgets'' path prefixes.
Another possible solution is to keep both algorithms and choose between them depending on the lenght of input.


\section{TNFA construction}\label{section_tnfa}

TNFA construction is given by the function $tn\!f\!a()$
that accepts IRE $r$ and state $y$, and returns TNFA for $r$ with final state $y$
(algorithm \ref{alg_tnfa}).
%
This precise construction is not necessary for the algorithms to work,
but it has a number of important properties.
\\[-0.5em]

\begin{itemize}[itemsep=0.5em]
    \item Non-essential $\epsilon$-transitions are reduced, as they make closure algorithms slower.

    \item Bounded repetition $r^{n,m}$ is unrolled in a way
        that duplicates $r$ exactly $m$ times %(fewer is not possible, unless automata with counters are used)
        and factors out common path prefixes:
        subautomaton for $(k+1)$-th iteration is only reachable from subautomaton for $k$-th iteration.
        For example, $a^{2,5}$ is unrolled as $aa(\epsilon | a (\epsilon | a (\epsilon | a)))$, not as $aa(\epsilon|a|aa|aaa)$.
        This ensures that the tag tree build by $\epsilon$-closure is a prefix tree.

    \item Priorities are assigned so as to make it more likely
        that depth-first traversal of the $\epsilon$-closure will find short paths before long paths.
        POSIX has four main rules: (1) longest, (2) leftmost, (3) no optional empty repetitions, and (4) empty match is better than no match.
        We cannot accommodate (1) with priorities, but we can accommodate (2), (4) and to some extent (3).
        This makes a great difference for GOR1 in pathological cases
        like $(((\epsilon)^{0,100})^{0,100})^{0,100})$,
        where there are many ambiguous paths with equal height.
        If GOR1 finds the shortest path early, then all other paths are just cancelled at the nearest join point,
        but in the opposite case GOR1 has to schedule configurations for re-scan after every improvement.
        Arguably this bias is a weakness of GOR1, and GTOP is more robust in this respect.

    \item Negative tags include tags for all nested subexpressions, in no particular order.
        Such tags are not needed for disambiguation (only the topmost pair is used),
        but they are necessary to reset submatch values that remain from previous iterations.

    \item Passing the final state $y$ in $tn\!f\!a()$ function
        allows to link subautomata in a simple way.
    \\
\end{itemize}

\begin{algorithm}[] \DontPrintSemicolon \SetKwProg{Fn}{}{}{} \label{alg_tnfa}
\begin{multicols}{2}
\setstretch{0.9}

    \newcommand \retonfa {tn\!f\!a}
    \newcommand \ntag {ntags}

    \Fn {$\underline{\retonfa(r, y)} \smallskip$} {
        \If {$r = (0, 0, \epsilon)$} {
            \Return $(\Sigma, \{y\}, \emptyset, \emptyset, y, y)$
        }
        \BlankLine
        \ElseIf {$r = (0, 0, \alpha) \mid_{\alpha \in \Sigma}$} {
            \Return $(\Sigma, \{x,y\}, \emptyset, \{(x, \alpha, \epsilon, y)\}, x, y)$
        }
        \BlankLine
        \ElseIf {$r = (0, 0, r_1 \cdot r_2)$} {
            $(\Sigma, Q_2, T_2, \Delta_2, x, y) = \retonfa (r_2, y)$ \;
            $(\Sigma, Q_u, T_u, \Delta_2, z, x) = \retonfa (r_1, x)$ \;
            \Return $(\Sigma, Q_1 \cup Q_2, T_1 \cup T_2, \Delta_1 \cup \Delta_2, z, y)$
        }
        \BlankLine
        \ElseIf {$r = (0, 0, r_1 \mid r_2)$} {
            $(\Sigma, Q_2, T_2, \Delta_2, x_2, y) = \retonfa (r_2, y)$ \;
            $(\Sigma, Q'_2, T_2, \Delta'_2, x'_2, y) = \ntag (T_2, y)$ \;
            $(\Sigma, Q_1, T_1, \Delta_1, x_1, x'_2) = \retonfa (r_2, x'_2)$ \;
            $(\Sigma, Q'_1, T_1, \Delta'_1, x'_1, x_2) = \ntag (T_1, x_2)$ \;
            $Q = Q_1 \cup Q'_1 \cup Q_2 \cup Q'_2 \cup \{x\}$ \;
            $\Delta = \Delta_1 \cup \Delta'_1 \cup \Delta_2 \cup \Delta'_2 \cup \big\{ (x,1,\epsilon,x_1), (x,2,\epsilon,x'_1) \big\}$ \;
            \Return $(\Sigma, Q, T_1 \cup T_2, \Delta, x, y)$
        }
        \BlankLine
        \ElseIf {$r = (0, 0, r_1^{n,m}) \mid_{1 < n \leq m \leq \infty}$} {
            $(\Sigma, Q_1, T_1, \Delta_1, x, y) = \retonfa ((0, 0, r_1^{n-1,m-1}), y)$ \;
            $(\Sigma, Q_2, T_2, \Delta_2, z, x) = \retonfa (r_1, x)$ \;
            \Return $(\Sigma, Q_1 \cup Q_2, T_1 \cup T_2, \Delta_1 \cup \Delta_2, z, y)$
        }
        \BlankLine
        \ElseIf {$r = (0, 0, r_1^{0,m})$} {
            $(\Sigma, Q_1, T_1, \Delta_1, x_1, y) = \retonfa ((0, 0, r_1^{1,m}), y)$ \;
            $(\Sigma, Q'_1, T_1, \Delta'_1, x'_1, y) = \ntag (T_1, y)$ \;
            $Q = Q_1 \cup Q'_1 \cup \{x\}$ \;
            $\Delta = \Delta_1 \cup \Delta'_1 \cup \big\{ (x, 1, \epsilon, x_1), (x, 2, \epsilon, x'_1) \big\}$ \;
            \Return $(\Sigma, Q, T_1, \Delta, x, y)$
        }
        \BlankLine
        \ElseIf {$r = (0, 0, r_1^{1,\infty})$} {
            $(\Sigma, Q_1, T_1, \Delta_1, z, x) = \retonfa (r_1, \Xund)$ \;
            $Q = Q_1 \cup \{y\}$ \;
            $\Delta = \Delta_1 \cup \big\{ (x, 1, \epsilon, z), (x, 2, \epsilon, y) \big\}$ \;
            \Return $(\Sigma, Q, T_1, \Delta, z, y)$
        }
        \BlankLine
        \ElseIf {$r = (0, 0, r_1^{1,1})$} {
            \Return $\retonfa (r_1, y)$
        }
        \BlankLine
        \ElseIf {$r = (0, 0, r_1^{1,m}) \mid_{1 < m < \infty}$} {
            $(\Sigma, Q_1, T_1, \Delta_1, x, y) = \retonfa ((0, 0, r_1^{1,m-1}), y)$ \;
            $(\Sigma, Q_2, T_2, \Delta_2, w, z) = \retonfa (r_1, z)$ \;
            $\Delta = \Delta_1 \cup \Delta_2 \cup \big\{ (z, 1, \epsilon, y), (z, 2, \epsilon, x) \big\}$ \;
            \Return $(\Sigma, Q_1 \cup Q_2, T_1 \cup T_2, \Delta, w, y)$
        }
        \BlankLine
        \ElseIf {$r = (i, j, r_1) \mid_{i \neq 0}$} {
            $(\Sigma, Q_1, T_1, \Delta_1, z, x) = \retonfa ((0, 0, r_1), x)$ \;
            $Q = Q_1 \cup \{w, y\}$ \;
            $T = T_1 \cup \big\{ (2i\!-\!1, j), (2i, j) \big\}$ \;
            $\Delta = \Delta_1 \cup \big\{ (w, 1, 2i\!-\!1, z), (x, 1, 2i, y) \big\}$ \;
            \Return $(\Sigma, Q, T, \Delta, w, y)$
        }
    }
    \BlankLine
    \BlankLine

    \Fn {$\underline{\ntag(T, y)} \smallskip$} {
        $\big\{ (t_1, \Xund), \hdots, (t_n, \Xund) \big\} = T$ \;
        $Q = \{x_0, \dots, x_n, y\}$ \;
        $\Delta = \big\{ (x_{i-1},1,-t_i, x_{i}) \big\}_{i=1}^{n}$ \;
        \Return $(\Sigma, Q, T, \Delta, x_0, y)$ \;
    }

    \vfill

\columnbreak

    \nonl \includegraphics[width=\linewidth]{img/tnfa_construction.pdf}

\end{multicols}
\vspace{0em}
\caption{TNFA construction.}
\end{algorithm}


\section*{Appendix}

\subsection{Correctness of $\epsilon$-closure construction}
\setcounter{XLem}{0}

For a given RT $r$,
we say that PE $\alpha$ is \emph{minimal} if $\alpha = PE(t)$ for some minimal $t \in PT(r)$,
and we say that path $\pi$ in TNFA $F(r)$ is \emph{minimal} if $\pi$ induces a minimal PE.

GOR1 correctness proof consists of two parts.
First, we get rid of $\epsilon$-loops by showing that,
on one hand, minmal paths do not contain $\epsilon$-loops,
and on the other hand, GOR1 cancels all paths which contain $\epsilon$-loops.
Second, for paths without $\epsilon$-loops we show right distributivity of path comparison over path concatenation.
The proofs make use of the TNFA nested structure
and the fact that each sub-TNFA is has a unique entry and exit states.
TNFA construct for all possible types of RT are shown on the fugure below.


\iffalse
\begin{figure}\label{fig_gor1}
\includegraphics[width=\linewidth]{img/gor1.pdf}
\caption{
Sub-TNFA for individual sub-RT with submatch groups: \\
(a) -- union, (b) -- product, (c), (d) -- bounded repetition, (e), (f) -- unbounded repetition.
}
\end{figure}
\fi

    \begin{XLem}\label{gor1_path_containment}
    Let $r$ be a RE, $\pi = q_1 \overset {\alpha} {\rightsquigarrow} q_2$ a tagged path in TNFA $F(r)$,
    where $\alpha \neq \epsilon$,
    and $h = minh (\alpha)$ the minimal tag height on path $\pi$.
    The following statements are true:
    \begin{enumerate}
        \item There is a position $p$ of length $|p| = h$
            such that $\pi$ fully lies inside of subautomaton $F(r|_p)$.

        \item There no position $p$ of length $|p| > h$
            such that $\pi$ fully lies inside of subautomaton $F(r|_p)$.
    \end{enumerate}
    Proof.
    Obvious from TNFA construction.
    $\square$
    \end{XLem}


\begin{XLem}\label{gor1_minpaths}
\lemmaclosureminpaths
\\[0.5em]
    % Proof in terms of REs and correspondence between subexpression and loop
    % is a bit hard because of unrolling of repetition in TNFA construction
    % (there is no direct correspondence between sub-RE and sub-TNFA).
    Proof.
    Suppose, on the contrary, that $\pi$ is a minimal path in TNFA $F(r)$, and that $\pi$ contains at least one $\epsilon$-loop.
    Consider the \emph{last} $\epsilon$-loop in $\pi$:
    it can only come from sub-TNFA of the form $F\big( (i, \Xund, (i_1, \Xund, r_1)^{n,\infty}) \big)$ where $n \geq 0$,
    as this is the only looping TNFA construct.
    Let $w_n$ be the final state of sub-TNFA $F\big( (i_1, \Xund, r_1) \big)$
    as shown on figure \ref{fig_gor1} (e) -- (f).
    Then $\pi$ can be represented as
    $\pi = \pi_1 \pi_2 \pi_3$, where $\pi_2$ is the $\epsilon$-loop:
    $\pi_1 = q_0 \overset {u | \alpha} {\rightsquigarrow} w_n$ and
    $\pi_2 = w_n \overset {\epsilon | \beta} {\rightsquigarrow} w_n$ and
    $\pi_3 = w_n \overset {v | \gamma} {\rightsquigarrow} q_f$.
    Consider path $\pi' = \pi_1 \pi_3$ that is obtained from $\pi$ by removing $\pi_2$.
    It consumes the same input string $uv$ as $\pi$,
    therefore PE transduced by $\pi$ and $\pi'$ are comparable: $\alpha \beta \gamma, \alpha \gamma \in PE(r, uv)$.
    Let $j$ be the total number of repetitions through $F\big( (i_1, \Xund, r_1) \big)$,
    and let $i$ be the index of the $\epsilon$-loop repetition.
    Consider two cases:

    \begin{enumerate}[itemsep=0.5em]
    \item[(1)]
    $i = j$.
    In this case fork of $\alpha \beta \gamma$ and $\alpha \gamma$ happens immediately after $(i-1)$-th repetition:
    %
    \begin{alignat*}{10}
        \alpha \beta \gamma &= x_0 \Xl_{h-1} \;&&\; \Xl_h x_1 \Xr_h \hdots \Xl_h x_{i-1} \Xr_h \;&&\big|\; \Xl_h x_{i} \Xr_h \;&&\; \Xr_{h-1} x_{j+1} \\[-0.5em]
        \alpha \gamma       &= x_0 \Xl_{h-1} \;&&\; \Xl_h x_1 \Xr_h \hdots \Xl_h x_{i-1} \Xr_h \;&&\big|\;                   \;&&\; \Xr_{h-1} x_{j+1}
    \end{alignat*}
    %
    Since $x_i$ is an $\epsilon$-loop, it is contained in the fork frame of $\alpha \beta \gamma$.
    We have $minh (\beta) = h$ and $minh (\gamma) \leq h - 1$, therefore $\rho_k = \rho'_k \leq h - 1$.
    Subsequent frames $l > k$ (if any) are identical and thus $\rho_l = \rho'_l$.
    Furthermore, $first (\gamma) = \Xr < \Xl = first (\beta)$.
    Therefore $\alpha \beta \gamma \sim \alpha \gamma$ and $\alpha \gamma \subset \alpha \beta \gamma$.

    \item[(2)]
    $i < j$.
    In this case $(i + 1)$-th repetition cannot be an $\epsilon$-loop
    (because we assumed that $i$-th repetition is the \emph{last} $\epsilon$-loop),
    therefore
    fork of $\alpha \beta \gamma$ and $\alpha \gamma$ happens
    inside of $i$-th repetition of $\alpha \beta \gamma$
    and $(i + 1)$-th repetition of $\alpha \gamma$:
    %
    \begin{alignat*}{10}
        \alpha \beta \gamma &= x_0 \Xl_{h-1} \;&&\; \Xl_h x_1 \Xr_h \hdots \Xl_h x_{i-1} \Xr_h \Xl_h y_1 \;&&\big|\; y_2 \Xr_h \Xl_h x_{i+1} && \Xr_h \Xl_h x_{i+2} \Xr_h \hdots \Xl_h x_j \Xr_h \;&&\; \Xr_{h-1} x_{j+1} \\[-0.5em]
        \alpha \gamma       &= x_0 \Xl_{h-1} \;&&\; \Xl_h x_1 \Xr_h \hdots \Xl_h x_{i-1} \Xr_h \Xl_h y_1 \;&&\big|\; y_3                     && \Xr_h \Xl_h x_{i+2} \Xr_h \hdots \Xl_h x_j \Xr_h \;&&\; \Xr_{h-1} x_{j+1}
    \end{alignat*}
    %
    Here $y_1 y_2 = x_i$ and $y_1 y_3 = x_{i+1}$ ($i$-th iteration is missing from $\alpha \gamma$).
    Fragment $y_2$ is part of the $\epsilon$-loop,
    therefore fork frame of $\alpha \beta \gamma$ contains parenthesis $\Xr_h$ and we have $\rho_k = h$.
    On the other hand, $y_3$ contains alphabet symbols,
    because $x_{i+1}$ is not an $\epsilon$-loop and $y_1$ is a part of the $\epsilon$-loop.
    Therefore fork frame of $\alpha \gamma$ ends in $y_3$ and we have $\rho'_k > h$.
    %
    %In this case
    %fork frame of $\alpha \beta \gamma$ contains $y_2 \Xr_h \Xl_h$ fragment, because $y_2$ is part of the $\epsilon$-loop.
    %But the fork frame of $\alpha \gamma$ ends inside of $y_3$, because $(i+1)$-th repetiton is not an $\epsilon$-loop and must contain alphabet symbols.
    %Therefore at the fork frame $k$ we have $\rho_k = h$ and $\rho'_k > h$.
    %
    All subsequent frames $l > k$ are identical:
    if they contain parentheses of height less than $h$, then $\rho_l = \rho'_l < h$;
    otherwise $\rho_l \leq h$ and $\rho'_l > h$.
    Therefore $\alpha \gamma \sqsubset \alpha \beta \gamma$.

    \end{enumerate}

    In both cases $\alpha \gamma < \alpha \beta \gamma$,
    which contradicts the fact that $\pi$ is a minimal path.
    $\square$

\end{XLem}


\iffalse
    \begin{XLem}\label{gor1_loops}
    GOR1 discards paths with tagged $\epsilon$-loops.
    \\
    Proof.

    GOR1 finds non-looping paths before their looping counterparts,
    as it uses depth-first search to explore new paths and prunes ambiguous paths
    immediately after exploring transitions to the join state.
    So for each TNFA state, the first path to be found is a path without $\epsilon$-loops.
    We will show that once GOR1 has found a path without $\epsilon$-loops,
    it will never prefer a path with an $\epsilon$-loop
    (though of course it might prefer some other path without $\epsilon$-loops).

    The only TNFA construct that has a loop is unbounded repetition
    $F\big( (i, \Xund, (i_1, \Xund, r_1)^{n,\infty}) \big)$ where $n \geq 0$,
    shown on figure \ref{fig_gor1} (e) -- (f).
    Consider arbitrary path $\pi$ that contains
    $\epsilon$-loop through sub-TNFA $F\big( (i_1, \Xund, r_1) \big)$.
    %
    Let $q_1$ be the first state on $\pi$ that belongs to the $\epsilon$-loop.
    %
    Path $\pi$ can be represented as $\pi = \pi_1 \pi_2 \pi_3$, where
    $\pi_1 = q_0 \overset {u | \alpha} {\rightsquigarrow} q_1$ and
    $\pi_2 = q_1 \overset {\epsilon | \beta} {\rightsquigarrow} q_1$ and
    $\pi_3 = q_1 \overset {v | \gamma} {\rightsquigarrow} q_f$.
    %
    By the time GOR1 finds path $\pi_1 \pi_2$,
    it must have already found some other path $\pi'_1 = q_0 \overset {u | \alpha'} {\rightsquigarrow} q_1$ without $\epsilon$-loops.
    There are two possible cases: either $\alpha' = \alpha$, or $\alpha' < \alpha$.
    We will show that in both cases $\alpha' < \alpha \gamma$
    and consequently, GOR1 prefers the path without the $\epsilon$-loop.
    Let $k$ be the index of the last frame
    and $\big( (\rho_1, \hdots, \rho_k), (\rho'_1, \hdots, \rho'_k) \big) = traces (\alpha', \alpha \gamma)$.

    First case: $\alpha' = \alpha$.
    Because $\alpha$ is a proper prefix of $\alpha \gamma$,
    fork happens at the last frame and we have
    $\rho_k = lasth(\alpha)$ and
    $\rho'_k = min (lasth(\alpha), minh(\gamma))$.
    If $lasth(\alpha) > minh(\gamma)$, then $\rho_k > \rho'_k$ and $\alpha \sqsubset \alpha \gamma$.
    Otherwise $\rho_k = \rho'_k$ and $\alpha \sim \alpha \gamma$,
    and we have $first(\alpha \backslash \alpha \gamma) = \bot$ and $first(\alpha \gamma \backslash \alpha) \neq \bot$,
    therefore $\alpha \subset \alpha \gamma$.
    In both cases $\alpha < \alpha \gamma$.

    Second case: $\alpha' < \alpha$.
    Let $\big( (\sigma_1, \hdots, \sigma_k), (\sigma'_1, \hdots, \sigma'_k) \big) = traces (\alpha', \alpha)$.
    We have $\rho_k = \sigma_k$ and $\rho'_k = min (\sigma'_k, minh(\gamma)) \leq \sigma_k$.
    If $minh(\gamma) < \sigma'_k$ then $\rho_k > \rho'_k$ and $\alpha' \sqsubset \alpha \gamma$.
    Otherwise $\rho'_k = \sigma'_k$.
    If $\alpha' \sqsubset \alpha$ then $\alpha' \sqsubset \alpha \gamma$.
    Otherwise $\alpha' \sim \alpha$ and $\alpha' \subset \alpha$.
    None of $\alpha$ and $\alpha'$ is a proper prefix of the other,
    because otherwise the longer path has an $\epsilon$-loop through $q_1$, which contradicts our assumption about $\pi_1$ and $\pi'_1$.
    Therefore $first (\alpha' \backslash \alpha) = first (\alpha' \backslash \alpha \gamma)$
    and $first (\alpha \backslash \alpha') = first (\alpha \gamma \backslash \alpha')$.
    Consequently $\alpha' \subset \alpha \implies \alpha' \subset \alpha \gamma$.
    Thus $\alpha' < \alpha \gamma$.
    $\square$
    \end{XLem}
\fi




    \begin{XLem}
    \lemmaclosurerightdist
    \\[0.5em]
    Proof.
    Let $k = |u|$ be the number of frames in $\alpha$ and $\beta$.
    Let
    $\big( (\rho_1, \hdots, \rho_k),$ $(\rho'_1, \hdots, \rho'_k) \big) = traces (\alpha, \beta)$ and
    $\big( (\sigma_1, \hdots, \sigma_k),$ $(\sigma'_1, \hdots, \sigma'_k) \big) = traces (\alpha \gamma, \beta \gamma)$.
    Obviously for frames $i < k$ we have $\rho_i = \sigma_i$ and $\rho'_i = \sigma'_i$,
    and for the last frame $k$ we have
    $\sigma_k = min (\rho_k, minh (\gamma))$ and
    $\sigma'_k = min (\rho'_k, minh (\gamma))$.
    Consider two possible cases.

    First case: $\alpha \sim \beta \wedge \alpha \subset \beta$.
    %
    We show that $\alpha \gamma \sim \beta \gamma \wedge \alpha \gamma \subset \beta \gamma$.
    %
    We have $\rho_i = \rho'_i \; \forall i$, therefore
    $\sigma_i = \sigma'_i \; \forall i$ and consequently $\alpha \gamma \sim \beta \gamma$.
    Let
    $x = first (\alpha \backslash \beta)$,
    $y = first (\beta \backslash \alpha)$,
    $x' = first (\alpha \backslash \beta \gamma)$ and
    $y' = first (\beta \backslash \alpha \gamma)$.
    None of $\pi_\alpha$ and $\pi_\beta$ is a proper prefix of another,
    otherwise the longer path must contain $\epsilon$-loop through $q_1$
    (because $\alpha$ and $\beta$ have the same number of frames).
    Consequently $x = x'$ and $y = y'$, and we have
    $\alpha \subset \beta$
    $\implies$
    $x < y$
    $\implies$
    $x' < y'$
    $\implies$
    $\alpha \gamma \subset \beta \gamma$.

    Second case: $\alpha \sqsubset \beta$.
    We show that $\alpha \gamma \sqsubset \beta \gamma$.
    %
    If $\rho_k = \rho'_k$ then $\sigma_k = \sigma'_k$
    and obviously $\alpha \gamma \sqsubset \beta \gamma$.
    Else it must be $\rho_k > \rho'_k$.
    In this case, if $minh (\gamma) > \rho'_k$, then $\sigma_k > \sigma'_k$ and again $\alpha \gamma \sqsubset \beta \gamma$.
    Else $minh (\gamma) \leq \rho'_k$ and $\sigma_k = \sigma'_k$.
    In this case, if $k > 1$ and $\rho_{k-1} > \rho'_{k-1}$ then again $\alpha \gamma \sqsubset \beta \gamma$.
    %
    In other words, the only possible case when $\gamma$ can change comparison result is
    when at the last frame we have $\rho_k > \rho'_k$,
    the appended suffix $\gamma$ contains parentheses with low height $minh (\gamma) \leq \rho'_k$
    (so that $\sigma_k = \sigma'_k$),
    and the previous frame doesn't exist
    or compares differently from the last frame: $k = 1$ or $\rho_{k-1} \leq \rho'_{k-1}$.
    We show that in this case the extended path $\pi_\beta \pi_\gamma$ must contain $\epsilon$-loop,
    which contradicts to the lemma condiitons.

    Consider the fragments of paths $\pi_\alpha$ and $\pi_\beta$ from fork to join,
    including (if it exists) the $\epsilon$-transition to the fork state:
    $\pi_\alpha' = q_2 \overset {u | \alpha'} {\rightsquigarrow} q_1$ and
    $\pi_\beta' = q_2 \overset {u | \beta'} {\rightsquigarrow} q_1$.
    We know that $minh (\alpha') = \rho_k$.
%    (because $\rho_k$ is set to the minimal parenthesis height on the path from fork to join).
    Therefore by lemma \ref{gor1_path_containment}
    we know that $\pi_\alpha'$ is contained in a subautomaton $f$ of height $\rho_k$.
    Likewise we know that $\pi_\beta'$ is not contained in $f$, because $minh (\beta') = \rho'_k < \rho_k$.
    %
    Let $\pi_\beta''$ be the part of $\pi_\beta'$ containing the last $k$-th frame,
    and note the following:
    \begin{enumerate}
        \item[(a)] the start state of $\pi_\beta''$ must be contained in $f$
            (because by our assumption
            either $k = 1$ and then start state of $\pi_\beta''$ is the fork state,
            or $\rho_{k-1} \leq \rho'_{k-1}$ which implies $\rho'_{k-1} \geq \rho_k$
            and then all but the last frames of $\pi_\beta'$ must be contained in $f$)
        \item[(b)] $\pi$ cannot be contained in $f$
            (because by our assumption $\rho_k > \rho'_k$)
        \item[(c)] the end state of $\pi_\beta''$ is contained in $f$
            (because it's the join state $q_1$ of $\pi_\alpha'$ and $\pi_\beta'$)
        \item[(d)] $\pi_\gamma$ is not contained in $f$
            (because by our assumption $minh (\gamma) \leq \rho'_k$ and consequently $minh (\gamma) < \rho_k$)
    \end{enumerate}
    %
    Put together, items (a) - (d) mean that the $\epsilon$-path $\pi_\beta'' \pi_\gamma$
    first leaves subautomaton $f$, then re-enters $f$, and then leaves $f$ second time.
    Because $f$ has a unique exit state, this means that $\pi_\beta'' \pi_\gamma$ contains $\epsilon$-loop
    through the exit state of $f$, which contradicts lemma conditions.
    (Effectively it means that $\pi_\beta \pi_\gamma$ is non-minimal and would be discarded by GOR1 anyway.)
%   Note that $\pi_\beta'$ itself does not necessarily contain $\epsilon$-loop.
    %
    $\square$
    \end{XLem}

\subsection*{Proof of Theorem \ref{theorem_order_on_IPTs}}

    \begin{XLem}\label{lemma_ptorder_antisymmetry}
    The order on IPTs is antisymmetric: if $t < s$, then $s \not< t$.
    \\
    Proof.

    Suppose, on the contrary, that $t <_p s$ and $s <_q t$ for some $p$, $q$.
    Without loss of generality let $p \leq q$.
    On one hand $t <_p s$ implies $\|t\|_p > \|s\|_p$.
    On the other hand $s <_q t$ implies $\|t\|_p \leq \|s\|_p$.
    Contradicting the assumption.
    $\square$
    \end{XLem}

    \begin{XLem}\label{lemma_ptorder_transitivity}
    The order on IPTs is transitive: if $t < s$ and $s < u$, then $t < u$.
    \\
    Proof.

    Let $t <_p s$ and $s <_q u$ for some positions $p$, $q$, and let $r = min (p, q)$.
    \\[-1em]

    First, we show that $\|t\|_r > \|u\|_r$.
    If $p \leq q$, we have $\|t\|_p > \|s\|_p$ (implied by $t <_p s$)
    and $\|s\|_p \geq \|u\|_p$ (implied by conjunction $s <_q u \wedge p \leq q$),
    therefore $\|t\|_p > \|u\|_p$.
    Otherwise $p > q$, we have $\|s\|_q > \|u\|_q$ (implied by $s <_q u$)
    and $\|t\|_q = \|s\|_q$ (implied by conjunction $t <_p s \wedge q < p$),
    therefore $\|t\|_q > \|u\|_q$.
    \\[-1em]

    Second, we show that $\forall r' < r$ it holds that $\|t\|_{r'} = \|u\|_{r'}$.
    We have $\|t\|_{r'} = \|s\|_{r'}$ (implied by conjunction $t <_p s \wedge r' < p$)
    and $\|s\|_{r'} = \|u\|_{r'}$ (implied by conjunction $s <_q u \wedge r' < q$),
    therefore $\|t\|_{r'} = \|u\|_{r'}$.
    $\square$
    \end{XLem}

    \begin{XLem}\label{incomparability_equivdef}
    $t \sim s \Leftrightarrow \; \forall p : \|t\|_p = \|s\|_p$.
    \\
    Proof.

    $\Rightarrow$. %First, we show $t \sim s \Rightarrow \forall p : \|t\|_p = \|s\|_p$.
    Suppose, on the contrary, that $\exists p = min \{ q \mid \|t\|_q \neq \|s\|_q \}$,
    then either $t <_p s$ (if $\|t\|_p > \|s\|_p$), or $s <_p t$ (if $\|t\|_p < \|s\|_p$).
    Both cases contradict $t \sim s$.
    \\[-1em]

    $\Leftarrow$.
    $\forall p : \|t\|_p = \|s\|_p$ implies
    $\nexists p : t <_p s$ and $\nexists q : s <_q t$,
    which implies $t \sim s$.
    $\square$
    \end{XLem}

    \begin{XLem}\label{lemma_ptorder_transitivity_of_incomparability}
    Incomparability relation on parse trees is transitive: if $t \sim s$ and $s \sim u$, then $t \sim u$.
    \\
    Proof.

    By lemma \ref{incomparability_equivdef} we have
    $t \sim s \Rightarrow \forall p : \|t\|_p = \|s\|_p$ and
    $s \sim u \Rightarrow \forall p : \|s\|_p = \|u\|_p$,
    therefore by lemma \ref{incomparability_equivdef} $\forall p : \|t\|_p = \|u\|_p \Rightarrow t \sim u$.
    $\square$
    \end{XLem}

The proof of theorem \ref{theorem_order_on_IPTs}
follows from
the lemma \ref{lemma_ptorder_antisymmetry},
the lemma \ref{lemma_ptorder_transitivity} and
the lemma \ref{lemma_ptorder_transitivity_of_incomparability}.


\subsection*{Proof of Theorem \ref{theorem_order_compat}}

First, we prove an auxilary lemma \ref{lemma_subtrees} which
shows that comparison of sub-IPT is justified
if the s-norms at all preceding submatch positions are equal.

    \begin{XLem}\label{lemma_subtrees}
    If $t, s \in \IPT(r, w)$ and $\exists p \in Sub(t) \cup Sub(s)$ such that $\snorm{t}{q} = \snorm{s}{q} \; \forall q \leq p$,
    then $\exists \widetilde{r}, \widetilde{w} : t|_p, s|_p \in \IPT(\widetilde{r}, \widetilde{w})$.
    \\
    Proof.
    By induction on position $p$.
    \\[-1em]

    Induction basis: the case of $p = \Lambda$ is trivial: let $\widetilde{r} = r$, $\widetilde{w} = w$.
    \\[-1em]

    Induction step: we have $|p| > 0$, let $p = p'.i$, where $i \in \YN$.
    Let $t' = t|_{p'} = T(t_1, \dots, t_n)$,
        $s' = s|_{p'} = T(s_1, \dots, s_m)$.
    By induction hypothesis $\exists r', w' : t', s' \in \IPT(r', w')$,
    where $w' = str(t_1) \dots str(t_n) = str(s_1) \dots str(s_m)$.
    \\[-1em]

    Next, we show that $str(t_i) = str(s_i)$.
    It must be that $i \in Sub(s') \cap Sub(t')$,
    otherwise only one of $\|t'\|_i$, $\|s'\|_i$ is $\infty$,
    which contradicts lemma condiiton $\|t\|_p = \|s\|_p$.
    Consider position $j \leq i$.
    Because the set of submatch positions contains siblings, we have $j \in Sub(s') \cap Sub(t')$.
    Consequently, $\|t'\|_j = |str(t_j)|$ and $\|s\|_j = |str(s_j)|$.
    By lemma condition we have $\|t\|_{p'.j} = \|s\|_{p'.j}$,
    therefore $\|t'\|_j = \|s'\|_j$,
    therefore $|str(t_j)| = |str(s_j)|$.
    Because $str(t_1) \dots str(t_n) = str(s_1) \dots str(s_m)$,
    we have $str(t_i) = str(s_i)$.
    \\[-1em]

    Now, let $\widetilde{w} = str(t_i)$.
    If $r' = r_1|r_2$ or $r' = r_1 r_2$, let $\widetilde{r} = r_i$.
    Otherwise, $r' = r_1^{k,l}$, let $\widetilde{r} = r_1$.
    $\square$
    \end{XLem}


    Proof of theorem \ref{theorem_order_compat}.
    \\[-1em]

    Consider any $t \in T_{min}$.
    For each position $p \in Sub(t)$, which is not itself a prefix of another position in $Sub(t)$,
    consider subtree $t' = t|_p$.
    It is an IPT for some sub-IRE $r'$ and substring $w'$: $t' \in \IPT(r', w')$.
    Let $t''$ be the $<$-minimal tree in $\IPT(r', w')$ and substitute $t'$ with $t''$ in $t$.
    (Note that substitutions are independent and can be performed in any order.)
    Let $u$ be the tree resulting from all such substitutions.
    By lemma \ref{incomparability_equivdef} we have $u \sim t$
    (because substitutions preserve the s-norm of subtrees at positions in $Sub(t)$),
    and so $u \in T_{min}$.
    We will show that $u = t_{min}$.
    \\[-1em]

    Suppose, on the contrary, that $u \neq t_{min}$.
    %
    Then we have $t_{min} <_p u$ for some non-submatch decision position $p$.
    Let $p = p'.p''$, where $p'$ is the longest prefix of $p$ that is a submatch position: $p' \in Sub(u) \cup Sub(t_{min})$.
    \\[-1em]

    It must be that for all submatch positions $q' < p'$ we have $\snorm{u}{q'} = \snorm{t_{min}}{q'}$,
    because $u \in T_{min}$ and thus either $u \sim t_{min}$,
    or $u \prec_q t_{min}$ for some $q \in Sub(u) \cup Sub(t_{min})$
    (in which case it must be $q > p$, because $u \prec_q t_{min}$ implies $\snorm{u}{q} > \snorm{t_{min}}{q}$,
    which in turn implies $\pnorm{u}{q} > \pnorm{t_{min}}{q}$,
    which contradicts $t_{min} <_p u$ if $q \leq p$).
    \\[-1em]

    Therefore by lemma \ref{lemma_subtrees} we have $\exists r', w' : u|_{p'}, t_{min}|_{p'} \in \IPT(r', w')$.
    On one hand, $t_{min} <_{p'.p''} u$ implies $t_{min}|_{p'} <_{p''} u|_{p'}$.
    But on the other hand, $p' \in Sub(u)$ and $p'$ is not itself a prefix of another position in $Sub(u)$,
    therefore $u|_{p'}$ is $<$-minimal by construction of $u$.
    Contradiction.
%    
%    %
%    On one hand, $u <_q \widetilde{s}$ for some submatch position $q$ (because $u \in P_{min}$).
%    On the other hand, $s \lessdot_p \widetilde{u}$ for some non-submatch position $p < q$ (because $s$ is $\lessdot$-minimal).
%    %
%    Let $p = p'.p''$, where $p'$ is the longest prefix of $p$ in $Sub(\widetilde{s}) \cup Sub(u)$.
%    It must be $\|u\|_{q'} = \|\widetilde{s}\|_{q'} \forall q' \leq p'$ (because $p' < q$ and $u <_q \widetilde{s}$),
%    and $p' \in Sub(u)$ (otherwise $\|u\|_{p'} = \infty \neq \|\widetilde{s}\|_{p'}$).
%    %
%    Now, by lemma \ref{lemma_subtrees} we have $\exists r', w' : u|_{p'}, \widetilde{s}|_{p'} \in PT(r', w')$,
%    therefore $s \lessdot_{p'.p''} u$ implies $s|_{p'} \lessdot_{p''} \widetilde{u}|_{p'}$.
%    But $p' \in Sub(u)$ and $p'$ is not itself a prefix of another position in $Sub(u)$,
%    therefore $\widetilde{u}|_{p'}$ is $\lessdot$-minimal by construction of $u$.
%    Contradiction.
    $\square$


\subsection*{Proof of Theorem \ref{theorem_order_on_pe_same_as_on_pt}}

    \begin{XLem}\label{lemma_pe_order_antisymm}
    The longest-leftmost-precedence relation $<$ is antisymmetric:
    if $\alpha < \beta$, then $\beta \not< \alpha$.
    \\
    Proof.
    Suppose, on the contrary, that $\alpha < \beta$ and $\beta < \alpha$.
    Let $\big( (\rho_0, \dots, \rho_n), (\rho'_0, \dots, \rho'_n) \big) = traces(\alpha, \beta)$.

    \medskip

    If $\exists i = max \{j \mid \rho_j \neq \rho'_j \}$, then
    $\alpha < \beta \implies \alpha \sqsubset \beta \implies \rho_i > \rho'_i$, but
    $\beta < \alpha \implies \beta \sqsubset \alpha \implies \rho'_i > \rho_i$. Contradiction.

    \medskip

    Otherwise $\rho_i = \rho'_i \; \forall i$, then
    $\alpha < \beta \implies \alpha \sim \beta \wedge \alpha \subset \beta$ and
    $\beta < \alpha \implies \beta \sim \alpha \wedge \beta \subset \alpha$.
    Let
    $x = first (\alpha \backslash \beta)$,
    $y = first (\beta \backslash \alpha)$, then
    $\alpha \subset \beta \implies x < y$, but
    $\beta \subset \alpha \implies y < x$. Contradiction.
    $\square$
    \end{XLem}


    \begin{XLem}\label{lemma_pe_equiv}
    Let $s, t \in PT(r, w)$.
    If $s \sim t$, then $\Phi_{h}(s) = \Phi_{h}(t) \; \forall h$.
    \\
    Proof.
    By induction on the height of $r$.

    \medskip

    Induction basis.
    For RT of height $1$ we have
    $| PT(r, w) | \leq 1 \; \forall w$,
    therefore $s = t$ and $\Phi_{h}(s) = \Phi_{h}(t)$.

    \medskip

    Induction step.
    We have
    $s = T^{d} (s_1, \dots, s_n)$ and
    $t = T^{d} (t_1, \dots, t_m)$.
    If $d = 0$, then $\Phi_{h}(s) = str(s) = w = str(t) = \Phi_{h}(t)$.
    Otherwise $d \neq 0$.
    By lemma \ref{incomparability_equivdef} we have $s \sim t \Rightarrow \forall p: \|s\|_p = \|t\|_p$.
    This implies $n = m$ (otherwise the norm of subtree at position $min(n,m)+1$ is $\infty$ for only one of $s$, $t$).
    Therefore
    $\Phi_{h}(s) = \Xl_{h+1} \Phi_{h+1}(s_1), \dots, \Phi_{h+1}(s_n) \Xr_h$ and
    $\Phi_{h}(t) = \Xl_{h+1} \Phi_{h+1}(t_1), \dots, \Phi_{h+1}(t_n) \Xr_h$.
%    Consider any $i \leq n$.
    It suffices to show that $\forall i \leq n: \Phi_{h+1}(s_i) = \Phi_{h+1}(t_i)$.
    We have $\forall p: \|s_i\|_p = \|t_i\|_p$ (implied by $\forall p: \|s\|_p = \|t\|_p$),
    therefore by lemma \ref{incomparability_equivdef} we have $s_i \sim t_i$,
    and by lemma \ref{lemma_subtrees} $\exists r', w': s_i, t_i \in PT(r', w')$,
    where the height of $r'$ is less than the height of $r$.
    By induction hypothesis $\Phi_{h+1}(s_i) = \Phi_{h+1}(t_i)$.
    $\square$
    \end{XLem}


    \begin{XLem}\label{lemma_pe_less_1}
    Let $s, t \in PT(r, w)$.
    If $s <_p t$ and $|p| = 1$, then $\Phi_{h}(s) < \Phi_{h}(t) \; \forall h$.
    \\
    Proof.

    By lemma conditions $|p| = 1$, which implies that $s$ and $t$ are compound PT
    $s = T^{d} (s_1, \dots, s_n)$ and 
    $t = T^{d} (t_1, \dots, t_m)$, where
    $d \neq 0$
    (because $\Lambda$ is a prefix of decision position $p$).
    Therefore $\Phi_{h}(s)$, $\Phi_{h}(t)$ can be represented as follows,
    where $k$ is the number of frames and $j$ is the fork:
    \begin{alignat*}{7}
        \Phi_{h}(s) &\;=\; \Xl_{h+1} &&\Phi_{h+1}(s_1) &&\dots &&\Phi_{h+1}(s_n) \Xr_h
            &&\;=\; \beta_0 a_1 \dots a_j \beta_j &&\;\big|\; && \gamma_j a_{j + 1} \dots a_k \gamma_k \\[-0.5em]
        \Phi_{h}(t) &\;=\; \Xl_{h+1} &&\Phi_{h+1}(t_1) &&\dots &&\Phi_{h+1}(t_m) \Xr_h
            &&\;=\; \beta_0 a_1 \dots a_j \beta_j &&\;\big|\; && \delta_j a_{j + 1} \dots a_k \delta_k
    \end{alignat*}
%
    By lemma conditions $|p| = 1$, therefore $p \in \YN$.
    Consider any $i \in \YN$ such that $i < p$.
    By lemma conditions $s <_p t$, which means
    $\|s\|_p > \|t\|_p \wedge \|s\|_q = \|t\|_q \;\forall q < p$.
    In particular $\|s_i\|_q = \|t_i\|_q \;\forall q$,
    therefore by lemma \ref{incomparability_equivdef} $s_i \sim t_i$
    and by lemma \ref{lemma_pe_equiv} we have $\Phi(s_i) = \Phi(t_i)$.
    Let $traces (\Phi_{h}(s), \Phi_{h}(t)) = \big( (\rho_0, \dots, \rho_k), (\rho'_0, \dots, \rho'_k) \big)$
    and consider the following cases.

    \medskip

    First case:
    $\infty = \|s_p\| > \|t_p\|$.
    In this case $s|_p$ does not exist
    (because $p$ corresponds to a submatch position in $r$,
    therefore $p \in Pos(s)$ implies $p \in Sub(s)$,
    which contradicts $\|s_p\| = \infty$).
    Fork happens immediately after $\Phi_{h+1}(s_{p-1})$, $\Phi_{h+1}(t_{p-1})$:
    \begin{alignat*}{7}
        \Phi_{h}(s) &\;=\; \Xl_{h+1} &&\Phi_{h+1}(s_1) &&\dots &&\Phi_{h+1}(s_{p-1})
            &&\;\big|\; \Xr_{h}         &&      && \\[-0.5em]
        \Phi_{h}(t) &\;=\; \Xl_{h+1} &&\Phi_{h+1}(t_1) &&\dots &&\Phi_{h+1}(t_{p-1})
            &&\;\big|\; \Phi_{h+1}(t_p) &&\dots &&\Phi_{h+1}(t_m) \Xr_{h}
    \end{alignat*}
    %
    In this case fork frame is the last frame: $j = k$, and therefore $\rho_j = \rho'_j = h$
    (because $\gamma_j$ and $\delta_j$ contain the closing parenthesis $\Xr_{h}$).
    For all $i < j$ we have $\rho_i = \rho'_i = -1$, therefore $\Phi_{h}(s) \sim \Phi_{h}(t)$.
    Furthermore, $first(\gamma_j)$ is $\Xr$ and $first(\delta_j)$ is one of $\Xl$ and $\Xm$,
    therefore $\Phi_{h}(s) \subset \Phi_{h}(t)$.
    Consequently $\Phi_{h}(s) < \Phi_{h}(t)$.

    \medskip

    Second case: $\infty > \|s_p\| > \|t_p\| = -1$.
    In this case both $s_p$ and $t_p$ exist,
    $s_p$ is not $\varnothing$ and $t_p$ is $\varnothing$,
    and fork happens immediately after $\Phi_{h+1}(s_{p-1})$, $\Phi_{h+1}(t_{p-1})$:
    \begin{alignat*}{8}
        \Phi_{h}(s) &\;=\; \Xl_{h+1} &&\Phi_{h+1}(s_1) &&\dots &&\Phi_{h+1}(s_{p-1})
            &&\;\big|\; \Xl_{h+1} \; x \; \Xr_{h+1} \; &&\Phi_{h+1}(s_{p+1}) &&\dots &&\Phi_{h+1}(s_n) \Xr_{h} \\[-0.5em]
        \Phi_{h}(t) &\;=\; \Xl_{h+1} &&\Phi_{h+1}(t_1) &&\dots &&\Phi_{h+1}(t_{p-1})
            &&\;\big|\; \Xm_{h+1} \;\;\;\;\;\;         &&\Phi_{h+1}(t_{p+1}) &&\dots &&\Phi_{h+1}(t_m) \Xr_{h}
    \end{alignat*}
    %
    If $j$-th frame is the last, we have $\rho_j = \rho'_j = h$ like in the first case.
    Otherwise we have $\rho_j = \rho'_j = h + 1$,
    because $minh(\gamma_j)$, $minh(\delta_j) \geq h + 1$
    and $lasth (\beta_j) = h + 1$
    (because if $p = 1$ then $\beta_j = \Xl_{h+1}$, otherwise
    $s_{p-1}$ exists and the last parenthesis in $\beta_j$
    is last parenthesis of $\Phi_{h+1}(s_{p-1})$, which is either $\Xr_{h+1}$ or $\Xm_{h+1}$).
    For subsequent frames $i$ such that $j < i < k$ we have $\rho_i = \rho'_i = h + 1$
    (because $minh(\gamma_j)$, $minh(\delta_j) \geq h + 1$),
    and for the last pair of frames we have $\rho_k = \rho'_k = h$.
    So in this case again $\Phi_{h}(s) \sim \Phi_{h}(t)$.
    Furthermore, $first (\gamma_j) = \Xl < \Xm = first (\delta_j)$, therefore $\Phi_{h}(s) \subset \Phi_{h}(t)$
    and $\Phi_{h}(s) < \Phi_{h}(t)$.

    \medskip

    Third case: $\infty > \|s_p\| > \|t_p\| \geq 0$.
    In this case both $s_p$ and $t_p$ exist and none of them is $\varnothing$,
    and fork happens somewhere after the opening parenthesis $\Xl$
    and before the closing parenthesis $\Xr$ in $\Phi_{h}(s_p)$, $\Phi_{h}(t_p)$:
    \begin{alignat*}{9}
        \Phi_{h}(s) &\;=\; \Xl_{h+1} &&\Phi_{h+1}(s_1) &&\dots &&\Phi_{h+1}(s_{p-1}) &&\; \Xl_{h+2} \; x
            &&\;\big|\; y \; \Xr_{h+1} \; &&\Phi_{h+1}(s_{p+1}) &&\dots &&\Phi_{h+1}(s_n) \Xr_{h} \\[-0.5em]
        \Phi_{h}(t) &\;=\; \Xl_{h+1} &&\Phi_{h+1}(t_1) &&\dots &&\Phi_{h+1}(t_{p-1}) &&\; \Xl_{h+2} \; x
            &&\;\big|\; z \; \Xr_{h+1} \; &&\Phi_{h+1}(t_{p+1}) &&\dots &&\Phi_{h+1}(t_m) \Xr_{h}
    \end{alignat*}
    %
    Let $l$ be an index such that the frame $\delta_l$ contains the closing parenthesis $\Xr_{h+1}$ of $\Phi_{h+1}(t_p)$.
    It must be $l \geq j$ (equality is possible due to non-fully parenthesized expressions,
    as in the example $(a|aa)^{0,\infty}$ shown on figure \ref{fig_pe3}).
    Because $\|s_p\| > \|t_p\|$,
    the closing parenthesis $\Xr_{h+1}$ of $\Phi_{h+1}(s_p)$ is not contained in $\gamma_{l}$,
    and $l$-th frame is not the last one.
    Therefore $minh (\gamma_l) \geq h+2$ and $minh (\delta_l) = h+1$.
    Furthermore, $minh(x)$, $minh(y)$, $minh(z) \geq h + 2$,
    therefore $lasth(\beta_j) \geq h+2$ and
    for all frames $j \leq i < l$ (if such $i$ exist) we have $\rho_i, \rho'_i \geq h+2$
    (note that it might be $\rho_i < \rho'_i$).
    For the $l$-th frame $\rho_l \geq h+2 > h+1 = \rho'_l$.
    For subsequent frames $\gamma_i$, $\delta_i$ such that $l < i < k$ we have
    $minh(\gamma_i)$, $minh(\delta_i) \geq h + 1$,
    therefore $\rho_i \geq h+1 = \rho'_i$.
    For the last pair of frames $\rho_k = \rho'_k = h$.
    Therefore in this case $\Phi_{h}(s) \sqsubset \Phi_{h}(t)$,
    which implies $\Phi_{h}(s) < \Phi_{h}(t)$.
    $\square$
    \end{XLem}


    \begin{XLem}\label{lemma_pe_less}
    Let $s, t \in PT(r, w)$.
    If $s <_p t$, then $\Phi_{h}(s) < \Phi_{h}(t) \; \forall h$.
    \\
    Proof.
    By induction on the length of $p$.

    \medskip

    Induction basis for $|p| = 1$ is given by lemma \ref{lemma_pe_less_1}.

    \medskip

    Induction step.
    Let $|p| \geq 2$, then $s$ and $t$ are compound PT
    $s = T^{d} (s_1, \dots, s_n)$ and
    $t = T^{d} (t_1, \dots, t_m)$, where
    $d \neq 0$ (because $\Lambda$ is a prefix of decision position $p$).
    %
    Furthermore, let $p = p'.p''$, where $p' \in \YN$.
    Subtrees $s' = s_{p'}$ and $t' = t_{p'}$ exist, because $p'$ a proper prefix of decision position $p$,
    and they also must be compount PT
    $s' = T^{d'} (s'_1, \dots, s'_{n'})$ and
    $t' = T^{d'} (t'_1, \dots, t'_{m'})$,
    because $|p''| > 0$, and it must be
    $d' \neq 0$ (because $p'$ is a prefix of decision position $p$).
    %
    For subtrees $s_i$ and $t_i$ where $i < p'$ we have
    $\|s_i\|_q = \|t_i\|_q \;\forall q$ (implied by $s <_p t$),
    therefore by lemma \ref{incomparability_equivdef}
    $s_i \sim t_i$, and by lemma \ref{lemma_pe_equiv} we have $\Phi_{h+1}(s_i) = \Phi_{h+1}(t_i)$.
    %
    Therefore $\Phi_{h}(s)$, $\Phi_{h}(t)$ can be represented as follows:
    \begin{alignat*}{9}
        \Phi_{h}(s)
            \;&=
                \;&& \Xl_{h+1} \Phi_{h+1}(s_1) \dots \Phi_{h+1}(s_{p'-1})
                \;&& \overbrace {\Xl_{h+2} \Phi_{h+2}(s'_1) \dots \Phi_{h+2}(s'_{n'}) \Xr_{h+1}}^{\Phi_{h+1}(s')}
                \;&& \Phi_{h+1}(s_{p'+1}) \Phi_{h+1}(s_n) \Xr_{h}
                \\
        \Phi_{h}(t)
            \;&=
                \;&& \Xl_{h+1} \Phi_{h+1}(t_1) \dots \Phi_{h+1}(t_{p'-1})
                \;&& \underbrace {\Xl_{h+2} \Phi_{h+2}(t'_1) \dots \Phi_{h+2}(t'_{m'}) \Xr_{h+1}}_{\Phi_{h+1}(t')}
                \;&& \Phi_{h+1}(t_{p'+1}) \Phi_{h+1}(t_m) \Xr_{h}
    \end{alignat*}

    We have $\|s\|_q = \|t\|_q \;\forall q < p'$ (implied by $s <_p t$),
    therefore by lemma \ref{lemma_subtrees} $\exists r', w' : s', t' \in PT(r', w')$.
    Moreover, $s' <_{p''} t'$ and $|p''| < |p|$, therefore by induction hypothesis $\Phi_{p+1}(s') < \Phi_{p+1}(t')$.
    %
    On the other hand, if $j$ is the fork and $f \leq j \leq k$ then
    $\Phi_{h}(s)$, $\Phi_{h}(t)$ can be represented as:
    \begin{alignat*}{9}
        \Phi_{h}(s)
            \;&=
                \;&& \beta_0 a_1 \dots a_f \beta_f^1
                \;&& \overbrace {\beta_f^2  a_{f+1} \dots a_j \beta_j \;\big|\; \gamma_j a_{j+1} \dots a_k \gamma_k^1}^{\Phi_{h+1}(s')}
                \;&& \gamma_k^2 a_{k+1} \dots a_l \gamma_l
                \\[-0.5em]
        \Phi_{h}(t)
            \;&=
                \;&& \beta_0 a_1 \dots a_f \beta_f^1
                \;&& \underbrace {\beta_f^2  a_{f+1} \dots a_j \beta_j \;\big|\; \delta_j a_{j+1} \dots a_k \delta_k^1}_{\Phi_{h+1}(t')}
                \;&& \delta_k^2 a_{k+1} \dots a_l \delta_l
    \end{alignat*}

%    \begin{alignat*}{9}
%        \Phi_{h}(s)
%            \;&=
%                \;&&\overbrace  {\Xl_{h+1} \Phi_{h+1}(s_1) \dots \Phi_{h+1}(s_{p'-1})}
%                    ^{\beta_0 a_1 \dots a_i \beta_i^1}
%                \;&&\overbrace  {\Xl_{h+2} \Phi_{h+2}(s'_1) \dots \Phi_{h+2}(s'_{n'}) \Xr_{h+1}}
%                    ^{\beta_i^2  a_{i+1} \dots a_j \beta_j \;\big|\; \gamma_j a_{j+1} \dots a_k \gamma_k^1}
%                \;&&\overbrace  {\Phi_{h+1}(s_{p'+1}) \Phi_{h+1}(s_n) \Xr_{h}}
%                    ^{\gamma_k^2 a_{k+1} \dots a_l \gamma_l}
%                \\
%        \Phi_{h}(t)
%            \;&=
%                \;&&\underbrace {\Xl_{h+1} \Phi_{h+1}(t_1) \dots \Phi_{h+1}(t_{p'-1})}
%                    _{\beta_0 a_1 \dots a_i \beta_i^1}
%                \;&&\underbrace {\Xl_{h+2} \Phi_{h+2}(t'_1) \dots \Phi_{h+2}(t'_{m'}) \Xr_{h+1}}
%                    _{\beta_i^2  a_{i+1} \dots a_j \beta_j \;\big|\; \delta_j a_{j+1} \dots a_k \delta_k^1}
%                \;&&\underbrace {\Phi_{h+1}(t_{p'+1}) \Phi_{h+1}(t_m) \Xr_{h}}
%                    _{\delta_k^2 a_{k+1} \dots a_l \delta_l}
%    \end{alignat*}

    Let $traces (\Phi_{h}(s), \Phi_{h}(t)) = \big( (\rho_0, \dots, \rho_l), (\rho'_0, \dots, \rho'_l) \big)$
    and $traces (\Phi_{h+1}(s'), \Phi_{h+1}(t')) = \big( (\sigma_h, \dots, \sigma_k), (\sigma'_h, \dots, \sigma'_k) \big)$.
    %
    We show that for frames $i$ such that $j \leq i < k$ we have
    $\rho_i = \sigma_i \wedge \rho'_i = \sigma'_i$,
    and for subsequent frames $k \leq i \leq l$ we have $\rho_i = \rho'_i$.

    \medskip

    First case: $i = j \leq k \leq l$ (the fork frame).
    Because $\Phi_{h+1}(s')$ and $\Phi_{h+1}(t')$ have nonempty common prefix $\Xl_{h+2}$,
    we have $lasht (\Phi_{h}(s) \sqcap \Phi_{h}(t)) = lasth (\Phi_{h+1}(s') \sqcap \Phi_{h+1}(t')) \geq h + 2$.
    %
    If $j < k$ then $minh (\gamma_j)$, $minh (\delta_j)$ are not affected by appending
    $\gamma^2_k$, $\delta^2_k$ and therefore $\rho_j = \sigma_j \wedge \rho'_j = \sigma'_j$.
    %
    Else if $j = k < l$ then we have $minh (\gamma^1_k) = minh (\delta^1_k) = h + 1$ and
    $minh (\gamma^2_k) = minh (\delta^2_k) \geq h + 1$, and
    therefore $\rho_j = \rho'_j = h + 1$.
    %
    Finally, if $j = l$ then $minh (\gamma_j) = minh (\delta_j) = h$ and $\rho_j = \rho'_j = h$.

    \medskip

    Second case: $j < i < k$.
    In this case the calculation of $\rho_i$, $\rho'_i$ depends on $\rho_j$, $\rho'_j$
    (for which we have shown $\rho_j = \sigma_j \wedge \rho'_j = \sigma'_j$) and
    is not affected by the appended $\gamma^2_k$, $\delta^2_k$, therefore
    $\rho_i = \sigma_i \wedge \rho'_i = \sigma'_i$.

    \medskip

    Third case: $j < i = k < l$. We have
    $minh (\gamma^1_k) = minh (\delta^1_k) = h + 1$ and
    $minh (\gamma^2_k) = minh (\delta^2_k) \geq h + 1$,
    and none of the preceding frames after the fork contain parentheses with height less than $h + 1$,
    therefore $\rho_k = \rho'_k = h + 1$.

    \medskip

    Fourth case: $k < i < l$.
    We have $\rho_i = \rho'_i = h + 1$,
    because $\rho_k = \rho'_k = h + 1$ and $minh(\gamma_i)$, $minh(\delta_i) \geq h + 1$.

    \medskip

    Fifth case: $i = l$.
    We have $\rho_l = \rho'_l = h$.

    \medskip

    So, we have shown that $\rho_i = \sigma_i \wedge \rho'_i = \sigma'_i$ for $j \leq i < k$
    and $\rho_i = \rho'_i$ for $k \leq i \leq l$.
    It trivially follows that $\Phi_{h+1}(s') \sqsubset \Phi_{h+1}(t')$ implies $\Phi_{h}(s) \sqsubset \Phi_{h}(t)$, and
    $\Phi_{h+1}(s') \sim \Phi_{h+1}(t')$ implies $\Phi_{h}(s) \sim \Phi_{h}(t)$.
    Because none of $\Phi_{h+1}(s')$, $\Phi_{h+1}(t')$ is a proper prefix of another,
    $\Phi_{h+1}(s') \subset \Phi_{h+1}(t')$ implies $\Phi_{h}(s) \subset \Phi_{h}(t)$.
    Therefore $\Phi_{h+1}(s') < \Phi_{h+1}(t')$ implies $\Phi_{h}(s) < \Phi_{h}(t)$.
    $\square$
    \end{XLem}


    Proof of theorem \ref{theorem_order_on_pe_same_as_on_pt}.
    \\[-1em]

    $\Rightarrow$. Given by lemma \ref{lemma_pe_less}.
    \\[-1em]

    $\Leftarrow$.
    We have $\Phi_{h}(s) < \Phi_{h}(t) \; \forall h$.
    Suppose that $\nexists p: s <_p t$.
    By lemma \ref{lemma_pe_order_antisymm} either $s = t$
    (in which case $\Phi_{h}(s) = \Phi_{h}(t)$, contradiction)
    or $t <_q s$ for some $q$
    (in which case $\Phi_{h}(t) < \Phi_{h}(s)$ by lemma \ref{lemma_pe_less}, contradiction).
    Therefore $\exists p: s <_p t$.
    $\square$


\end{document}

